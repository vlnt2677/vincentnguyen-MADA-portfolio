[
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "",
    "text": "Alexis Gonzalez contributed to this project.\n\nThe structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch to other formats, like html or pdf. See the Quarto documentation for other formats.\nWarning: package 'here' was built under R version 4.3.3\n\n\nWarning: package 'knitr' was built under R version 4.3.3"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.1 General Background Information",
    "text": "2.1 General Background Information\nThe analysis intends to seek if there associations between shoe size and preference to the physical characteristics of an individual like their height or weight."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.2 Description of data and data source",
    "text": "2.2 Description of data and data source\nThe data file, “exampledata2”, is located in the same folder as “exampledata”. Along with the same data found in “exampledata”, “exampledata2” contains two new columns, one numeric and one character. The first column is shoe size (specifically Men’s US sizing) and the second column is favorite shoe color. For shoe color, some colors show up more than others but I believe people tend to enjoy neutral colors more."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.3 Questions/Hypotheses to be addressed",
    "text": "2.3 Questions/Hypotheses to be addressed\nThe project analyzes characteristics like height, weight, shoe size, and favorite shoe size to find any associations. There is simple descriptive analysis but also linear model creation.\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the bibtex file specified in the YAML header above (here dataanalysis_template_references.bib) and have the right bibtex key. Then you can include like this:\nExamples of reproducible research projects can for instance be found in (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, Shen, & Handel, 2020)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 Data aquisition",
    "text": "3.1 Data aquisition\nAs applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.2 Data import and cleaning",
    "text": "3.2 Data import and cleaning\nWrite code that reads in the file and cleans it so it’s ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.3 Statistical analysis",
    "text": "3.3 Statistical analysis\nExplain anything related to your statistical analyses."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.1 Exploratory/Descriptive analysis",
    "text": "4.1 Exploratory/Descriptive analysis\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\nTable 1 shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I recommend the here package, but I’m showing the other approach here just in case you encounter it.\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nfactor.ordered\nfactor.n_unique\nfactor.top_counts\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nFavorite Shoe Color\n0\n1\n4\n5\n0\n5\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nfactor\nGender\n0\n1\nNA\nNA\nNA\nNA\nNA\nFALSE\n3\nM: 4, F: 3, O: 2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nHeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n165.666667\n15.976545\n133\n156.0\n166\n178\n183\n▂▁▃▃▇\n\n\nnumeric\nWeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n70.111111\n21.245261\n45\n55.0\n70\n80\n110\n▇▂▃▂▂\n\n\nnumeric\nShoe Size (US/M)\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7.611111\n2.368778\n4\n6.5\n7\n10\n11\n▅▂▇▁▇"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.2 Basic statistical analysis",
    "text": "4.2 Basic statistical analysis\nTo get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any “p&lt;0.05 means statistical significance” interpretation is not valid.\nFigure 1 shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\n\n\n\nFigure 1: Height and weight stratified by gender.\n\n\n\n\n\n(Boxplot?) shows a box-plot figure produced by one of the R scripts. While limited by a small sample size, the figure shows that individuals with black or white as their favorite shoe color have a large variation in height.\n\n\n\n\n\nHeight stratified by favorite shoe color\n\n\n\n\n(Scatter?) shows a box-plot figure produced by one of the R scripts. Judging by the few data points available, there tends to be a positive association between shoe size and weight. Like the rest of the results, there is no significance detected here.\n\n\n\n\n\nWeight stratified by shoe size."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.3 Full analysis",
    "text": "4.3 Full analysis\nUse one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.\nExample Table 2 shows a summary of a linear model fit.\n\n\n\n\nTable 2: Linear model fit table.\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n149.2726967\n23.3823360\n6.3839942\n0.0013962\n\n\nWeight\n0.2623972\n0.3512436\n0.7470519\n0.4886517\n\n\nGenderM\n-2.1244913\n15.5488953\n-0.1366329\n0.8966520\n\n\nGenderO\n-4.7644739\n19.0114155\n-0.2506112\n0.8120871\n\n\n\n\n\n\n\n\nTable 3 shows a summary of a linear model fit. While this analysis is silly and insignificant, I will highlight some findings anyway. First, if an individual had a shoe size of 0, their height would be 134.8 cm. Next, for every increase in shoe size, there is a 3.8 cm increase in height. Additionally, individuals with their favorite shoe color as black tended to be 13.7 cm taller than those with favorite shoe color of white.\n\n\n\n\nTable 3: Linear model fit table for Height as outcome and Shoe Size and Favorite Shoe color as predictors.\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n143.839286\n23.600665\n6.0947132\n0.0088725\n\n\nShoe Size (US/M)\n3.803571\n2.796511\n1.3601133\n0.2669785\n\n\nFavorite Shoe ColorBlue\n-3.875000\n20.781334\n-0.1864654\n0.8639765\n\n\nFavorite Shoe ColorBrown\n-14.562500\n19.998256\n-0.7281885\n0.5191891\n\n\nFavorite Shoe ColorGreen\n-4.464286\n19.818211\n-0.2252618\n0.8362481\n\n\nFavorite Shoe ColorWhite\n-13.732143\n13.982553\n-0.9820912\n0.3984739"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.1 Summary and Interpretation",
    "text": "5.1 Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.2 Strengths and Limitations",
    "text": "5.2 Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.3 Conclusions",
    "text": "5.3 Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper (Leek & Peng, 2015) discusses types of analyses.\nThese papers (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, et al., 2020) are good examples of papers published using a fully reproducible setup similar to the one shown in this template.\nNote that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal are available. You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like, I just used the generic word references.bib but giving it a more descriptive name is probably better."
  },
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at /Users/cgnorris/Documents/GitHub/MADA (EPID 8060E)/vincentnguyen-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 3 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`      \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                 \n1 Height          height in centimeters                 numeric value &gt;0 or NA\n2 Weight          weight in kilograms                   numeric value &gt;0 or NA\n3 Gender          identified gender (male/female/other) M/F/O/NA              \n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 5\n$ Height                &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\",…\n$ Weight                &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 4…\n$ Gender                &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M…\n$ `Shoe Size (US/M)`    &lt;dbl&gt; 11.0, 10.0, 5.5, 10.0, 13.0, 5.0, 7.0, 8.0, 8.5,…\n$ `Favorite Shoe Color` &lt;chr&gt; \"Black\", \"White\", \"Green\", \"Blue\", \"Brown\", \"Bla…\n\nsummary(rawdata)\n\n    Height              Weight          Gender          Shoe Size (US/M)\n Length:14          Min.   :  45.0   Length:14          Min.   : 4.000  \n Class :character   1st Qu.:  55.0   Class :character   1st Qu.: 6.500  \n Mode  :character   Median :  70.0   Mode  :character   Median : 7.250  \n                    Mean   : 602.7                      Mean   : 7.821  \n                    3rd Qu.:  90.0                      3rd Qu.: 9.625  \n                    Max.   :7000.0                      Max.   :13.000  \n                    NA's   :1                                           \n Favorite Shoe Color\n Length:14          \n Class :character   \n Mode  :character   \n                    \n                    \n                    \n                    \n\nhead(rawdata)\n\n# A tibble: 6 × 5\n  Height Weight Gender `Shoe Size (US/M)` `Favorite Shoe Color`\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;                \n1 180        80 M                    11   Black                \n2 175        70 O                    10   White                \n3 sixty      60 F                     5.5 Green                \n4 178        76 F                    10   Blue                 \n5 192        90 NA                   13   Brown                \n6 6          55 F                     5   Black                \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nFavorite Shoe Color\n0\n1\n4\n5\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55.0\n70.00\n90.00\n7000\n▇▁▁▁▁\n\n\nShoe Size (US/M)\n0\n1.00\n7.82\n2.48\n4\n6.5\n7.25\n9.62\n13\n▅▇▃▅▂\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nFavorite Shoe Color\n0\n1\n4\n5\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165.0\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73.0\n90\n7000\n▇▁▁▁▁\n\n\nShoe Size (US/M)\n0\n1.00\n8.00\n2.48\n4\n6.50\n7.5\n10\n13\n▃▇▃▅▂\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nFavorite Shoe Color\n0\n1\n4\n5\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166.0\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73.0\n90\n7000\n▇▁▁▁▁\n\n\nShoe Size (US/M)\n0\n1.00\n8.00\n2.48\n4\n6.50\n7.5\n10\n13\n▃▇▃▅▂\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nFavorite Shoe Color\n0\n1\n4\n5\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.50\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.50\n70\n85\n110\n▇▂▃▃▂\n\n\nShoe Size (US/M)\n0\n1\n8.18\n2.67\n4\n6.75\n8\n10\n13\n▅▇▅▇▂\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFavorite Shoe Color\n0\n1\n4\n5\n0\n5\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.50\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.50\n70\n85\n110\n▇▂▃▃▂\n\n\nShoe Size (US/M)\n0\n1\n8.18\n2.67\n4\n6.75\n8\n10\n13\n▅▇▅▇▂\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nFavorite Shoe Color\n0\n1\n4\n5\n0\n5\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156.0\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55.0\n70\n80\n110\n▇▂▃▂▂\n\n\nShoe Size (US/M)\n0\n1\n7.61\n2.37\n4\n6.5\n7\n10\n11\n▅▂▇▁▇\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at /Users/cgnorris/Documents/GitHub/MADA (EPID 8060E)/vincentnguyen-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  character                1     \n  factor                   1     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable       n_missing complete_rate min max empty n_unique whitespace\n1 Favorite Shoe Color         0             1   4   5     0        5          0\n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable    n_missing complete_rate   mean    sd  p0   p25 p50 p75 p100\n1 Height                   0             1 166.   16.0  133 156   166 178  183\n2 Weight                   0             1  70.1  21.2   45  55    70  80  110\n3 Shoe Size (US/M)         0             1   7.61  2.37   4   6.5   7  10   11\n  hist \n1 ▂▁▃▃▇\n2 ▇▂▃▂▂\n3 ▅▂▇▁▇\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\np5 &lt;- mydata %&gt;% ggplot(aes(x=`Favorite Shoe Color`, y= Height, color=`Favorite Shoe Color` )) + geom_boxplot()\nplot(p5)\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"Heightcolorstratisfied.png\")\nggsave(filename = figure_file, plot=p5) \n\nSaving 7 x 5 in image\n\n\n\np6 &lt;- mydata %&gt;% ggplot(aes(x= Weight, y=`Shoe Size (US/M)`, color= Weight )) + geom_point()\nplot(p6)\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"Shoesizesweightstratisfied.png\")\nggsave(filename = figure_file, plot=p6)\n\nSaving 7 x 5 in image\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Data Visualization Exercise",
    "section": "",
    "text": "Coding Exercise for Week 6\nFirst, I asked ChatGPT the following:\n“Ok, I want to replicate a graph I found on this website, https://projects.fivethirtyeight.com/checking-our-work/nfl-games/,\nThis is the graph:\nCode in R, also I provided the data.”\nAfter feeding it the data, ChatGPT made the following graph:\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load the data (update filename if needed)\ndata_location &lt;- here::here(\"presentation-exercise\", \"covid_approval_polls.csv\")\ndata &lt;- read.csv(data_location)\n\n# Filter for Biden's approval ratings\ndata_biden &lt;- data %&gt;%\n  filter(subject == \"Biden\" & party == \"all\") %&gt;%\n  mutate(end_date = as.Date(end_date, format=\"%Y-%m-%d\"))\n\n# Plot the approval and disapproval ratings over time with smoothing\nggplot(data_biden, aes(x = end_date)) +\n  geom_point(aes(y = approve), color = \"#E15759\", alpha = 0.5) +\n  geom_smooth(aes(y = approve), color = \"#E15759\", linewidth = 1, span = 0.2, method = \"loess\", se = FALSE) +\n  geom_point(aes(y = disapprove), color = \"#9C7DE5\", alpha = 0.5) +\n  geom_smooth(aes(y = disapprove), color = \"#9C7DE5\", linewidth = 1, span = 0.2, method = \"loess\", se = FALSE) +\n  scale_x_date(date_breaks = \"2 months\", date_labels = \"%m/%y\") +\n  labs(title = \"Do Americans approve of Biden’s response to the coronavirus crisis?\",\n       subtitle = \"A calculation of the share of all Americans who approve of the president’s handling of the coronavirus outbreak\",\n       x = \"Date\",\n       y = \"Approval Rating (%)\",\n       color = \"Response\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAs you can see, the resulting graph was very smooth compared to the original. It has a line down the middle lacking any of the jaggedness of the original. For reference, here is the original one created by FiveThirtyEight.\n\n\n\nWith this next iteration, I asked ChatGPT to reintroduce some of the jaggedness of the original graph. It gave me a satisfactory graph but I tweaked the smoothing to try to get a bit closer to the original. In the end, it does not perfectly mimic the FiveThirtyEight graph, however, I think it looks pretty similar. I also added in a legend.\n\n# Load required libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n# Load the data (update filename if needed)\ndata_location &lt;- here::here(\"presentation-exercise\", \"covid_approval_polls.csv\")\ndata &lt;- read.csv(data_location)\n\n# Filter for Biden's approval ratings\ndata_biden &lt;- data %&gt;%\n  filter(subject == \"Biden\" & party == \"all\") %&gt;%\n  mutate(end_date = as.Date(end_date, format=\"%Y-%m-%d\")) %&gt;%\n  arrange(end_date) %&gt;%\n  mutate(approve_smooth = rollmean(approve, k = 12, fill = NA, align = \"right\"),\n         disapprove_smooth = rollmean(disapprove, k = 12, fill = NA, align = \"right\"))\n\n# Plot the approval and disapproval ratings over time\nggplot(data_biden, aes(x = end_date)) +\n  geom_point(aes(y = approve), color = \"#E15759\", alpha = 0.2) +\n  geom_line(aes(y = approve_smooth, color = \"Approve\"), linewidth = 0.8) +\n  geom_point(aes(y = disapprove), color = \"#9C7DE5\", alpha = 0.2) +\n  geom_line(aes(y = disapprove_smooth, color = \"Disapprove\"), linewidth = 0.8) +\n  scale_x_date(date_breaks = \"2 months\", date_labels = \"%m/%y\") +\n  labs(title = \"Do Americans approve of Biden’s response to the coronavirus crisis?\",\n       subtitle = \"A calculation of the share of all Americans who approve of the president’s handling of the coronavirus outbreak\",\n       x = \"Date\",\n       y = \"Approval Rating (%)\",\n       color = \"Response\") +\n  scale_color_manual(\n    values = c(\"Approve\" = \"#E15759\", \"Disapprove\" = \"#9C7DE5\")\n  ) +\n  theme_minimal()\n\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 11 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nCreating the table was a bit more tricky. At first, I had created a table with average approval and disapproval rates. Additionally, the table had a net approval column, subtracing disapproval from approval. Lastly, the original copy of the table had1 month change in approval and disapproval columns.\nTo better fit the requirements of the assignment, I needed to implement some form of color, boldness, and visual. I chose to color the observations corresponding to the approval and disapproval ratings, communicating changes in these values through saturation of color. I also wanted to bold the highest values, as they might be of most interest. For the visual, I chose to do a sparkline to track approval overtime. For these parts, I needed ChatGPT’s help as I was not familiar with these more advanced concepts. I took it one by one, first asking it to make the approval column green and increase it with intensity as it increased. I also prompted it to make disapproval red and increase the saturation with its increase as well. Next, I asked it to bold the highest values of the three columns of interest. Lastly, I asked ChatGPT to create sparklines for the approval trend overtime. I asked it to try to make it simple and to try not to utilize too many packages. The resulting product is below.\n\n# load required libraries\nlibrary(dplyr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(gt)\n\nWarning: package 'gt' was built under R version 4.3.3\n\nlibrary(gtExtras)\n\nWarning: package 'gtExtras' was built under R version 4.3.3\n\nlibrary(purrr)\n\n# aggregate the data by month and compute additional columns\nmonthly_data &lt;- data_biden %&gt;%\n  mutate(month = floor_date(end_date, \"month\")) %&gt;%\n  group_by(month) %&gt;%\n  summarise(\n    approve_avg    = mean(approve_smooth, na.rm = TRUE),\n    disapprove_avg = mean(disapprove_smooth, na.rm = TRUE),\n    net_approval   = mean(approve_smooth - disapprove_smooth, na.rm = TRUE)\n  ) %&gt;%\n  arrange(month) %&gt;%\n  mutate(\n    approve_trend    = approve_avg - lag(approve_avg),\n    disapprove_trend = disapprove_avg - lag(disapprove_avg)\n  ) %&gt;%\n  tail(12)  \n\n# create a list-column containing approval history up to each month\nmonthly_data &lt;- monthly_data %&gt;%\n  mutate(approval_history = map(seq_along(approve_avg), ~ approve_avg[1:.x]))\n\n# build the gt table with a sparkline column for approval trends\nmonthly_data %&gt;%\n  mutate(month = format(month, \"%B %Y\")) %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline(approval_history, type = \"default\") %&gt;%\n  cols_label(\n    month             = \"Month\",\n    approve_avg       = \"Avg Approval (%)\",\n    disapprove_avg    = \"Avg Disapproval (%)\",\n    net_approval      = \"Net Approval\",\n    approve_trend     = \"1-Month Approval Change\",\n    disapprove_trend  = \"1-Month Disapproval Change\",\n    approval_history  = \"Approval Trend\"  \n  ) %&gt;%\n  fmt_number(\n    columns  = c(approve_avg, disapprove_avg, net_approval, approve_trend, disapprove_trend),\n    decimals = 1\n  ) %&gt;%\n  \n  # color corresponding to gains in approval or disapproval\n  data_color(\n    columns = approve_avg,\n    colors  = scales::col_numeric(\n      palette = c(\"#E6F4EA\", \"#2E7D32\"),  \n      domain  = NULL\n    )\n  ) %&gt;%\n  data_color(\n    columns = disapprove_avg,\n    colors  = scales::col_numeric(\n      palette = c(\"#FDEDEC\", \"#C62828\"),  \n      domain  = NULL\n    )\n  ) %&gt;%\n  data_color(\n    columns = net_approval,\n    colors  = scales::col_numeric(\n      palette = c(\"#FFCCCC\", \"#FFFFFF\", \"#99FF99\"),  \n      domain  = NULL\n    )\n  ) %&gt;%\n\n  tab_header(\n    title    = \"Biden's Monthly COVID-19 Approval Ratings\",\n    subtitle = \"Averaged approval and disapproval ratings by month \"\n  ) %&gt;%\n  \n  # bold highest values for each column\n  tab_style(\n    style = list(cell_text(weight = \"bold\")),\n    locations = cells_body(\n      columns = approve_avg,\n      rows = approve_avg == max(approve_avg, na.rm = TRUE) \n    )\n  ) %&gt;%\n  tab_style(\n    style = list(cell_text(weight = \"bold\")),\n    locations = cells_body(\n      columns = disapprove_avg,\n      rows = disapprove_avg == max(disapprove_avg, na.rm = TRUE)  \n    )\n  ) %&gt;%\n  tab_style(\n    style = list(cell_text(weight = \"bold\")),\n    locations = cells_body(\n      columns = net_approval,\n      rows = net_approval == max(net_approval, na.rm = TRUE)  \n    )\n  ) %&gt;%\n\n  # make the font black\n  tab_style(\n    style = list(\n      cell_text(color = \"black\") \n    ),\n    locations = cells_body(\n      columns = everything()\n    )\n  ) %&gt;%\n  \ntab_footnote(\n    footnote = \"Approval ratings are shaded from light green (low) to dark green (high). Disapproval ratings are shaded from light red (low) to dark red (high). Net approval is colored from red (negative) to white (neutral) to green (positive). Bolded values indiciate the highest of this recorded time period.\",\n    locations = cells_column_labels(\n      columns = c(approve_avg, disapprove_avg, net_approval)\n    )\n  ) %&gt;%\n  \n  tab_options(\n    table.border.top.color    = \"black\",\n    table.border.bottom.color = \"black\",\n    heading.align             = \"center\"\n  )\n\nWarning: Since gt v0.9.0, the `colors` argument has been deprecated.\n• Please use the `fn` argument instead.\nThis warning is displayed once every 8 hours.\n\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiden's Monthly COVID-19 Approval Ratings\n\n\nAveraged approval and disapproval ratings by month\n\n\nMonth\nAvg Approval (%)1\nAvg Disapproval (%)1\nNet Approval1\n1-Month Approval Change\n1-Month Disapproval Change\nApproval Trend\n\n\n\n\nDecember 2021\n47.4\n45.4\n2.0\n−0.5\n0.0\n\n\n\n   47.4\n\n\n\nJanuary 2022\n44.5\n48.8\n−4.3\n−2.9\n3.4\n\n\n\n   44.5\n\n\n\nFebruary 2022\n44.8\n48.1\n−3.3\n0.3\n−0.7\n\n\n\n   44.8\n\n\n\nMarch 2022\n48.1\n44.1\n3.9\n3.2\n−4.0\n\n\n\n   48.1\n\n\n\nApril 2022\n48.4\n43.8\n4.5\n0.3\n−0.3\n\n\n\n   48.4\n\n\n\nMay 2022\n48.3\n43.4\n4.9\n−0.1\n−0.4\n\n\n\n   48.3\n\n\n\nJune 2022\n47.0\n43.5\n3.5\n−1.3\n0.1\n\n\n\n   47.0\n\n\n\nJuly 2022\n47.3\n42.4\n4.9\n0.3\n−1.1\n\n\n\n   47.3\n\n\n\nAugust 2022\n47.1\n42.9\n4.2\n−0.2\n0.5\n\n\n\n   47.1\n\n\n\nSeptember 2022\n49.1\n42.5\n6.6\n2.0\n−0.4\n\n\n\n   49.1\n\n\n\nOctober 2022\n50.1\n43.4\n6.7\n1.0\n1.0\n\n\n\n   50.1\n\n\n\nNovember 2022\n49.0\n43.0\n6.0\n−1.1\n−0.5\n\n\n\n   49.0\n\n\n\n\n1 Approval ratings are shaded from light green (low) to dark green (high). Disapproval ratings are shaded from light red (low) to dark red (high). Net approval is colored from red (negative) to white (neutral) to green (positive). Bolded values indiciate the highest of this recorded time period.\n\n\n\n\n\n\n\n\nOverall, ChatGPT served as a great tool to help replicate and create visualizations and tables. Throughout this assignment, I faced prompting issues as I was not as specific as I could have been. For example, when creating the table, color assignment was off as it started using red and purple from the graph. Also, some of the column labels were often vague, which required me to go in and edit the code as necessary."
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Placeholder file for the future R coding exercise.\nThis coding exercise begins with loading and checking the data using help(), str(), summary(), and class().\n\n# Loading and Checking Data\n\n# loading dslabs package\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.3.3\n\n# look at help file for gapminder data\nhelp(gapminder)\n\nstarting httpd help server ... done\n\n# get an overview of data structure\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n# get a summary of the data\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n# determine the type of object gapminder is\nclass(gapminder)\n\n[1] \"data.frame\"\n\n\nThis part of the exercise is titled, “Processing Data”, where objects are creating using the gapminder data set.\n\n# Processing Data\n\n# load tidyverse package\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# create new object/variable called africadata\nafricadata &lt;- gapminder %&gt;%\n  filter(continent == \"Africa\")\n\n# create a new object on only infant_mortality\ninfant_health &lt;- africadata %&gt;%\n  select(infant_mortality, life_expectancy)\n\n# Create a new object containing population and life_expectancy\noverall_health &lt;- africadata %&gt;%\n  select(population, life_expectancy)\n\n# inspect new objects\nstr(infant_health)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\nsummary(infant_health)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\nstr(overall_health)\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\nsummary(overall_health)\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51                         \n\n\nThis part of the exercise is titled, “Plotting”, and focuses on creating plots on the objects previously created. For the graph, “Life expectancy as a function of Population Size in Africa”, there is a streaking pattern which is caused by countries having several entries in different years. Countries tended to increase in life expectancy and size as years pass.\n\nlibrary(ggplot2)\n\n# create a scatter plot of life expectancy as a function of infant mortality\ninfant_graph &lt;- ggplot(africadata, aes(x = infant_mortality, y =life_expectancy)) + geom_point(alpha = 0.6, color = \"blue\") + labs(\n  title = \"Life expectancy as a function of Infant Mortality in Africa\",\n  x = \"Infant Mortality\",\n  y = \"Life Expectancy\"\n)\n\n# display graph\nprint(infant_graph)\n\nWarning: Removed 226 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n# create a scatter plot of life expectancy as a function of population size\npopulation_graph &lt;- ggplot(africadata, aes(x = population, y = life_expectancy)) + geom_point(alpha = 0.6, color = \"blue\") + scale_x_log10() + labs(\n  title = \"Life expectancy as a function of Population Size in Africa\",\n  x = \"Population (Log Scale)\",\n  y = \"Life Expectancy\"\n)\n\n# display graph\nprint(population_graph)\n\nWarning: Removed 51 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis part of the exercise is titled, “More data processing”. In this part, the data is inspected to figure out which years have the most missing counts. The assignment chooses the year 2000 to filter the data. I create an object called africadata_twothousand which contains the filtered data.\n\nna_count_per_year &lt;- africadata %&gt;%\n  filter(is.na(infant_mortality)) %&gt;%\n  group_by(year) %&gt;%\n  summarize(na_count_per_year = n())\n\n# print result\nprint(na_count_per_year)\n\n# A tibble: 23 × 2\n    year na_count_per_year\n   &lt;int&gt;             &lt;int&gt;\n 1  1960                10\n 2  1961                17\n 3  1962                16\n 4  1963                16\n 5  1964                15\n 6  1965                14\n 7  1966                13\n 8  1967                11\n 9  1968                11\n10  1969                 7\n# ℹ 13 more rows\n\n# create new object with only the year 2000\nafricadata_twothousand &lt;- africadata %&gt;%\n  filter(year == \"2000\")\n\n# check/inspect new object with data from the year 2000\nstr(africadata_twothousand)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\nsummary(africadata_twothousand)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n\nThis part of the exercise is called, “More plotting”. This is essentially identidical as a previous section but utilizes filtered data for only the year 2000.\n\n# create a scatter plot of life expectancy as a function of infant mortality\ninfant_graph_twothousand &lt;- ggplot(africadata_twothousand, aes(x = infant_mortality, y =life_expectancy)) + geom_point(alpha = 0.6, color = \"blue\") + labs(\n  title = \"Life expectancy as a function of Infant Mortality in Africa in the year 2000\",\n  x = \"Infant Mortality\",\n  y = \"Life Expectancy\"\n)\n\n# display graph\nprint(infant_graph_twothousand)\n\n\n\n\n\n\n\n# create a scatter plot of life expectancy as a function of population size\npopulation_graph_twothousand &lt;- ggplot(africadata_twothousand, aes(x = population, y = life_expectancy)) + geom_point(alpha = 0.6, color = \"blue\") + scale_x_log10() + labs(\n  title = \"Life expectancy as a function of Population Size in Africa in the year 2000\",\n  x = \"Population (Log Scale)\",\n  y = \"Life Expectancy\"\n)\n\n# display graph\nprint(population_graph_twothousand)\n\n\n\n\n\n\n\n\nThis part of the exercise is called, “Simple model fits”. This code creates a linear model using lm(). Model 1, “Fit1”, is a model with life expectancy as the outcome and infant mortality as the predictor. This model has a p-value of 2.826e-08. This indicates significance. Model 2, “Fit2”, is a model with population size as a predictor and life expectancy as the outcome. This model has a p-value of 0.6159. This indicates insignificance.\n\n# Fit Model 1 - Life Expectancy and Infant Mortality\nfit1 &lt;- lm(life_expectancy ~ infant_mortality, data = africadata_twothousand)\n\n# summary of fit model 1\nsummary(fit1)\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = africadata_twothousand)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      71.29331    2.42611  29.386  &lt; 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\n# Fit Model 2 - Life Expectancy and Population Size\nfit2 &lt;- lm(life_expectancy ~ population, data = africadata_twothousand)\n\n# summary of fit model 2\nsummary(fit2)\n\n\nCall:\nlm(formula = life_expectancy ~ population, data = africadata_twothousand)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.429  -4.602  -2.568   3.800  18.802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.593e+01  1.468e+00  38.097   &lt;2e-16 ***\npopulation  2.756e-08  5.459e-08   0.505    0.616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.524 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159\n\n\n\nThe following sections contributed by Guozheng Yang\n\n\nLoad packages and dataset\nI’m going to explore the murders dataset from the package dslabs. This dataset contains gun murder data for 2010 reported by FBI, and is sourced from Wikipedia. The dataset is organized by states, with the population of each state included.\n\n# Load required package\nlibrary(dslabs) # This package has the murders dataset\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(maps) # This package is used to make a map\n\nWarning: package 'maps' was built under R version 4.3.3\n\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n# Look at help file for murders data\nhelp(murders)\n\nFirst of all, let’s take a look at the data structure.\n\n# Determine the type of murders\nclass(murders)\n\n[1] \"data.frame\"\n\n# Get an overview of data structure\nstr(murders)\n\n'data.frame':   51 obs. of  5 variables:\n $ state     : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n $ abb       : chr  \"AL\" \"AK\" \"AZ\" \"AR\" ...\n $ region    : Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n $ population: num  4779736 710231 6392017 2915918 37253956 ...\n $ total     : num  135 19 232 93 1257 ...\n\n# Get a summary of data\nsummary(murders)\n\n    state               abb                      region     population      \n Length:51          Length:51          Northeast    : 9   Min.   :  563626  \n Class :character   Class :character   South        :17   1st Qu.: 1696962  \n Mode  :character   Mode  :character   North Central:12   Median : 4339367  \n                                       West         :13   Mean   : 6075769  \n                                                          3rd Qu.: 6636084  \n                                                          Max.   :37253956  \n     total       \n Min.   :   2.0  \n 1st Qu.:  24.5  \n Median :  97.0  \n Mean   : 184.4  \n 3rd Qu.: 268.0  \n Max.   :1257.0  \n\n# Check if there are missing values\nanyNA(murders)\n\n[1] FALSE\n\n\nAs shown, there are 51 observations and 5 variables in this dataset. 51 states and their abbreviations are listed. The states are also classified by their geographic locations. Two numeric variables denote the population and number of gun murders of each state in 2010. Luckily, we don’t have any NA in this dataset.\n\n\nMap plotting\nSince we have data from different states, I want to make a map to compare the different gun murder rates by states. Here I calculate the gun murder rates as the number of gun murders divided by the population of each state. Then I use a heatmap to color the statesby their gun murder rates. Of note, the US map data is in the package maps, with the longitude and latitude of each state included. This tool makes it convenient for us to draw the heatmap.\nLet’s take a look at the data from package maps first.\n\n# Extract the US map data\nus_map &lt;- map_data(\"state\")\n\n# Determine the type of murders\nclass(us_map)\n\n[1] \"data.frame\"\n\n# Get an overview of data structure\nstr(us_map)\n\n'data.frame':   15537 obs. of  6 variables:\n $ long     : num  -87.5 -87.5 -87.5 -87.5 -87.6 ...\n $ lat      : num  30.4 30.4 30.4 30.3 30.3 ...\n $ group    : num  1 1 1 1 1 1 1 1 1 1 ...\n $ order    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ region   : chr  \"alabama\" \"alabama\" \"alabama\" \"alabama\" ...\n $ subregion: chr  NA NA NA NA ...\n\n# Get a summary of data\nsummary(us_map)\n\n      long              lat            group           order      \n Min.   :-124.68   Min.   :25.13   Min.   : 1.00   Min.   :    1  \n 1st Qu.: -96.22   1st Qu.:33.91   1st Qu.:15.00   1st Qu.: 3899  \n Median : -87.61   Median :38.18   Median :26.00   Median : 7794  \n Mean   : -89.67   Mean   :38.18   Mean   :30.15   Mean   : 7798  \n 3rd Qu.: -79.13   3rd Qu.:42.80   3rd Qu.:47.00   3rd Qu.:11699  \n Max.   : -67.01   Max.   :49.38   Max.   :63.00   Max.   :15599  \n    region           subregion        \n Length:15537       Length:15537      \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\nAs shown, all state names are in stored in the region variable in lower case. Variables long and lat have the longitude and latitude of each state’s border. As this is a well prepared data, I will calculate gun murder rates in the murders dataset and then merge it into us_map.\n\n# Prepare the murders data\nmurders &lt;- murders %&gt;%\n  mutate(state_low=tolower(state), # Convert state names to lower case\n         rate=total/population) # Calculate gun murder rate\n\nmap_data &lt;- us_map %&gt;%\n  left_join(murders, by=c(\"region\"=\"state_low\"))\n\nAs the data for plotting is well prepared, I will use geom_polygon() function to draw the map and then color each state by gun murder rates. The geom_polygon() function is a useful tool for connecting a group of points by a certain order. In our case, it’s used to draw the border line of each state.\n\n# Draw a heatmap of gun murder rates\nus_gmr &lt;- ggplot(map_data, aes(x=long, y=lat, group=group, fill=rate))+\n  geom_polygon(color=\"steelblue4\", linewidth=1)+ # Draw border line of states\n  scale_fill_gradient(name=\"Gun murder rate\", \n                      low=\"white\", high=\"firebrick4\")+ # Define color gradient\n  theme_bw()+\n  labs(title=\"Gun murder rate by state\", x=\"Longitude\", y=\"Latitude\")+\n  theme(axis.title.x=element_text(size=10, color=\"black\", face=\"bold\"),\n        axis.title.y=element_text(size=10, color=\"black\", face=\"bold\"),\n        axis.text.x=element_text(color=\"black\", size=8),\n        axis.text.y=element_text(color=\"black\", size=8),\n        plot.title=element_text(size=15, color=\"black\", face=\"bold\"),\n        legend.position=\"right\",\n        legend.title=element_text(size=10, face=\"bold\"))\n\nus_gmr\n\n\n\n\n\n\n\n\nAs the map shows, the gun murder rate is higher overall in the southern US. For the northern US, the northwest has a lower gun murder rate than the northeast. This map demonstrate the geographic distribution of gun murder rates.\n\n\nModel fitting\nAs the response of interest is gun murder rate, it’s intuitive to fit a Poisson regression with a log link function. In the Poisson regression model, the number of gun murders is the response, and the population of each state is the offset. The region of states is a predictor to show if gun murder rate is different across different regions.\nBefore that, let’s make a grouped boxplot to see if the difference is evident. Here I use region as the X-axis and gun murder rate as the Y-axis.\n\nboxplot &lt;- ggplot(murders, aes(x=region, y=rate))+\n  geom_boxplot(color=\"firebrick3\", width=.5, linewidth=1)+\n  theme_bw()+\n  labs(title=\"Gun murder rate by region\", x=\"Region\", y=\"Gun murder rate\")+\n  theme(axis.title.x=element_text(size=10, color=\"black\", face=\"bold\"),\n        axis.title.y=element_text(size=10, color=\"black\", face=\"bold\"),\n        axis.text.x=element_text(color=\"black\", size=8),\n        axis.text.y=element_text(color=\"black\", size=8),\n        plot.title=element_text(size=15, color=\"black\", face=\"bold\"),\n        legend.position=\"right\",\n        legend.title=element_text(size=10, face=\"bold\"))\nboxplot\n\n\n\n\n\n\n\n\nAs shown, the gun murder rate in southern US is evidently higher compared to other regions. The northeast, north central region, and west of the US have similar gun murder rate, though the median in the west is a little lower.\nNow, let’s fit a Poisson regression model to see if the regional difference is statistically significant. As indicated by the map above, the southern US has a generally lower gun murder rate. So I want to use South as the reference group and adjust the factor levels of region.\n\n# Adjust factor level of region\nmurders$region_fct &lt;- factor(murders$region, levels=c(\"South\", \"North Central\", \"West\", \"Northeast\"))\n\n# Poisson regression: gun murder rate ~ region\npoi_fit &lt;- glm(total ~ region_fct, offset=log(population), family=\"poisson\", data=murders)\nsummary(poi_fit)\n\n\nCall:\nglm(formula = total ~ region_fct, family = \"poisson\", data = murders, \n    offset = log(population))\n\nCoefficients:\n                         Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)             -10.22464    0.01544 -662.24   &lt;2e-16 ***\nregion_fctNorth Central  -0.28349    0.02803  -10.12   &lt;2e-16 ***\nregion_fctWest           -0.31140    0.02760  -11.28   &lt;2e-16 ***\nregion_fctNortheast      -0.31162    0.03032  -10.28   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1570.6  on 50  degrees of freedom\nResidual deviance: 1361.1  on 47  degrees of freedom\nAIC: 1684.8\n\nNumber of Fisher Scoring iterations: 4\n\n# Exponential the coefficient for interpretation\nexp(poi_fit$coefficients)\n\n            (Intercept) region_fctNorth Central          region_fctWest \n           3.626558e-05            7.531479e-01            7.324233e-01 \n    region_fctNortheast \n           7.322624e-01 \n\n\nAccording to the output, the mean gun murder rate in southern US is 3.63e-5. The north central US has a 25% decrease in gun murder rate compared to southern US. The western and northeastern US both have about 27% decrease in gun murder rate than southern US. Notably, the coefficient for north central US, western US, and northeastern US are all negative with p-values lower than 0.05. We have enough evidence to reject the null hypothesis and conclude that the gun murder rates in these three regions are significantly lower compared to southern US."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Hello, I am Vincent Nguyen\n\n\nI am 4th year undergraduate student in the Double Dawgs program. I intend to pursue an MPH, specifically in Epidemiology. In the past, I have been involved in research labs that utilize R but definitely not to the extent MADA does. I have dabbled in statistical analysis, machine learning modeling, and more. This course I am to solidify my skills in R (I have used free courses, however, have felt the need for more formal training). I also want to explore more advanced and modern techniques in statistical analysis like machine learning.\n\nFun fact about me is that I love to play games and watch movies. Currently, I am a top ranked player in Fortnite (Top 1000!) and in Marvel Rivals (Top 3%). My favorite movies are Tenet and Star Wars The Force Awakens.\n\n\nCareer\nCurrently, I am involved in the Sundaram Lab at UGA and an intern for the CDC’s Division of Workforce Development. I aim to become an Epidemiologist or Biostatistician with the skills learned from this class! Some of my research interests include oncology, infectious disease ecology, and parasitology.\n\n\n\n\nHighlighted Data Analysis Technique\nThe application of simulated environments for analyzing changes in health policy is something I am greatly interested in. For example, this article details the use of EU-TOPIA, an evaluation tool designed to allow researchers use country-specific data to quantify the potential benefits and harms of diferent cancer guidelines in their respective country. Going forward, I believe the application of simulated environments can help bolster research at a low cost!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vincent Nguyen’s MADA Portfolio",
    "section": "",
    "text": "Created on 01/06/2025\n\nHello,\nWelcome to my website and data analysis portfolio for MADA.\n\nPlease use the Menu Bar above to look around.\nHave fun!"
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains a simple made-up data-set in an Excel file.\nIt contains the variables Height, Weight and Gender of a few imaginary individuals.\nThe dataset purposefully contains some faulty entries that need to be cleaned.\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Vincent Nguyen's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-acquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-acquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 Data acquisition",
    "text": "3.1 Data acquisition\nAs applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next."
  },
  {
    "objectID": "data-exercise/data-exercise.qmd.html",
    "href": "data-exercise/data-exercise.qmd.html",
    "title": "Data Exercise",
    "section": "",
    "text": "First, we will start with loading some necessary packages for data creation, visualization, and more.\n\n# loading dslabs package\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(here)\n\nhere() starts at C:/Users/vince/OneDrive/Desktop/port-MADA/vincentnguyen-MADA-portfolio\n\n\n\n\n\nSince the process is randomized, setting a seed can help improve reproduciblity when creating synthetic data.\n\n# set a seed for reproducibility\nset.seed(123)\n\n# define number of observations\nn_observations &lt;- 100\n\n\n\n\nNext, we will begin by creating the data itself. I chose to make a data set on an imaginary disease in an imaginary area. Each district has their region type (urban, suburban, or rural), case count, vaccination rate, population density, attack rate, and level of intervention (none, partial, or full) recorded. While in real life, these variables can heavily affect one , and especially the case count, for this exercise I chose to focus on a few interactions.\nFirst, population density is heavily dependent on the region type. Next, attack rates are affected by population density and intervention level. Lastly, the case count is affected by population density, vaccination rates, and level of intervention. At the end of this block, I created bounds that try to align with what is logically expected for these values.\n\n# create empty data frame with placeholders for variables\n\nsyn_data &lt;- data.frame(\n  DistrictID = numeric(n_observations),\n  RegionType = character(n_observations),\n  CaseCount = numeric(n_observations),\n  VaccinationRate = numeric(n_observations),\n  PopulationDensity = numeric(n_observations),\n  AttackRate = numeric(n_observations),\n  Intervention = character(n_observations)\n)\n\n# Variable 1: District ID\nsyn_data$DistrictID &lt;- 1:n_observations\n\n# Variable 2: Region Type (Categorical variable)\nsyn_data$RegionType &lt;- purrr::map_chr(sample(c(\"Urban\", \"Rural\", \"Suburban\"), n_observations, replace = TRUE), as.character)\n\n\n\n# Variable 4: Vaccination Rate\nsyn_data$VaccinationRate &lt;- runif(n_observations, min = 0.5, max = 1.0)\n\n# Variable 5: Population Density (per km squared)\nsyn_data$PopulationDensity &lt;- with(syn_data, ifelse(\n  RegionType == \"Urban\", rnorm(sum(RegionType == \"Urban\"), mean = 3000, sd = 500),\n  ifelse(RegionType == \"Suburban\", rnorm(sum(RegionType == \"Suburban\"), mean = 1000, sd = 300),\n         rnorm(sum(RegionType == \"Rural\"), mean = 100, sd = 50)\n  )\n))\n\n# Variable 7: Level of Public Health Intervention\nsyn_data$Intervention &lt;- purrr::map_chr(sample(c(\"None\", \"Partial\", \"Full\"), n_observations, replace = TRUE), as.character)\n\n# Variable 6: Attack Rate (Assisted with by ChatGPT)\nsyn_data$AttackRate &lt;- ifelse(\n  syn_data$RegionType == \"Urban\",\n  runif(n_observations, min = 0.05, max = 0.2) * ifelse(syn_data$Intervention == \"Full\", 0.7, 1.2),\n  runif(n_observations, min = 0.01, max = 0.15)\n)\n\n\n# Variable 3: Case Count (Numerical Variable) Assisted with by ChatGPT (moved down here to follow coding flow)\nsyn_data$CaseCount &lt;- round(\n  (200 / (syn_data$VaccinationRate * 2)) * \n  (syn_data$PopulationDensity / 1000) * \n  ifelse(syn_data$Intervention == \"Full\", 0.5, \n         ifelse(syn_data$Intervention == \"Partial\", 0.8, 1.0))\n)\n\n# Ensure logical bounds\nsyn_data$CaseCount &lt;- pmax(syn_data$CaseCount, 0)\nsyn_data$AttackRate &lt;- round(pmax(pmin(syn_data$AttackRate, 1), 0.01), 2)\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 50)  # Density cannot be negative\nsyn_data$VaccinationRate &lt;- round(syn_data$VaccinationRate, 2)  # Round vaccination rates\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 10)\n\n\n\n\nIn this section, I begin by looking at summary statistic for the data. After that, I begin exploring the data visually through various box and scatter plots.\n\n# Summary of data\nsummary(syn_data)\n\n   DistrictID      RegionType          CaseCount     VaccinationRate \n Min.   :  1.00   Length:100         Min.   :  3.0   Min.   :0.5100  \n 1st Qu.: 25.75   Class :character   1st Qu.: 15.0   1st Qu.:0.6375  \n Median : 50.50   Mode  :character   Median :100.0   Median :0.7450  \n Mean   : 50.50                      Mean   :145.1   Mean   :0.7531  \n 3rd Qu.: 75.25                      3rd Qu.:226.2   3rd Qu.:0.8500  \n Max.   :100.00                      Max.   :589.0   Max.   :0.9900  \n PopulationDensity   AttackRate     Intervention      \n Min.   :  50.0    Min.   :0.0100   Length:100        \n 1st Qu.: 123.0    1st Qu.:0.0600   Class :character  \n Median : 987.8    Median :0.0900   Mode  :character  \n Mean   :1380.6    Mean   :0.0973                     \n 3rd Qu.:2599.9    3rd Qu.:0.1300                     \n Max.   :3954.6    Max.   :0.2300                     \n\ndplyr::glimpse(syn_data) \n\nRows: 100\nColumns: 7\n$ DistrictID        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ RegionType        &lt;chr&gt; \"Suburban\", \"Suburban\", \"Suburban\", \"Rural\", \"Suburb…\n$ CaseCount         &lt;dbl&gt; 123, 28, 167, 10, 108, 5, 15, 6, 67, 291, 12, 5, 344…\n$ VaccinationRate   &lt;dbl&gt; 0.68, 0.99, 0.58, 0.55, 0.57, 0.85, 0.81, 0.95, 0.84…\n$ PopulationDensity &lt;dbl&gt; 840.72804, 561.47332, 1206.37503, 56.72436, 613.8908…\n$ AttackRate        &lt;dbl&gt; 0.14, 0.03, 0.10, 0.03, 0.01, 0.08, 0.02, 0.05, 0.07…\n$ Intervention      &lt;chr&gt; \"None\", \"Full\", \"Partial\", \"None\", \"None\", \"Full\", \"…\n\n# Region Case Count\nregion_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = RegionType)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_cases)\n\n\n\n\n\n\n\n# Intervention x Case Count\nintervention_cases &lt;- ggplot(syn_data, aes(x = Intervention, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Intervention Level\",\n                        x = \"Intervention Level\",\n                        y = \"Case Count\")\n\nprint(intervention_cases)\n\n\n\n\n\n\n\n# Region x Intervention x Case Count\nregion_intervention_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type and Intervention level\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_intervention_cases)\n\n\n\n\n\n\n\n# Population Density x Case Count\ndensity_cases &lt;- ggplot(syn_data, aes(x = PopulationDensity, y =CaseCount)) + geom_point() + theme_minimal() +\n    labs(title = \"Case Count by Population Density\",\n         x = \"Population Density (per km squared and Log Scaled)\",\n         y = \"Case Count\") +\n    scale_x_log10()\n\nprint(density_cases)\n\n\n\n\n\n\n\n\n\n\n\nFor the final part of this mini-exploration, I chose to conduct three analyses.\nFirst, I did a linear model with the 3 variables, population density, vaccination rate, and intervention. The adjusted R-squared of 0.9313 indicates that, after accounting for the number of predictors, 93.13% of the variance in case count is explained by the variables.\nNext, I looked at whether intervention levels significantly affected the case count of a district by using ANOVA. The p-value of 0.0104 indicates that there is a significant differences among intervention levels.\nLastly, principle component analysis was conducted for exploration purposes. The results indicate that PC1, Population Density, explains 65.1% of the variation seen in the case counts. PC2, vaccination rate, explains 33.12% and PC3, Intervention Level, explains 1.774%. With this in mind, models in the future can consider omitting PC3 because of its small contribution to variance.\n\n# Creation of Linear Model with 3 variables, population density, vaccination rate, and intervention\nlm_model_everything &lt;- lm(CaseCount ~ PopulationDensity + VaccinationRate + Intervention, data = syn_data)\nsummary(lm_model_everything)\n\n\nCall:\nlm(formula = CaseCount ~ PopulationDensity + VaccinationRate + \n    Intervention, data = syn_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-94.268 -20.001  -5.863  23.237 156.904 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.053e+01  2.377e+01   2.126 0.036077 *  \nPopulationDensity    1.057e-01  3.061e-03  34.531  &lt; 2e-16 ***\nVaccinationRate     -1.195e+02  2.974e+01  -4.018 0.000118 ***\nInterventionNone     7.019e+01  1.003e+01   6.999 3.63e-10 ***\nInterventionPartial  4.907e+01  9.107e+00   5.388 5.16e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.43 on 95 degrees of freedom\nMultiple R-squared:  0.934, Adjusted R-squared:  0.9313 \nF-statistic: 336.3 on 4 and 95 DF,  p-value: &lt; 2.2e-16\n\n# Creation of ANOVA to test if intervention levels signficantly affect case count\nanova_model &lt;- aov(CaseCount ~ Intervention, data = syn_data)\nsummary(anova_model)\n\n             Df  Sum Sq Mean Sq F value Pr(&gt;F)  \nIntervention  2  191028   95514   4.785 0.0104 *\nResiduals    97 1936247   19961                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Principle Component Analysis (suggested by ChatGPT) to view which variables explain the variance\npca_model &lt;- prcomp(syn_data[, c(\"PopulationDensity\", \"VaccinationRate\", \"CaseCount\")], center = TRUE, scale. = TRUE)\nsummary(pca_model)\n\nImportance of components:\n                         PC1    PC2     PC3\nStandard deviation     1.398 0.9968 0.23067\nProportion of Variance 0.651 0.3312 0.01774\nCumulative Proportion  0.651 0.9823 1.00000"
  },
  {
    "objectID": "data-exercise/data-exercise.qmd.html#package-loading",
    "href": "data-exercise/data-exercise.qmd.html#package-loading",
    "title": "Data Exercise",
    "section": "",
    "text": "First, we will start with loading some necessary packages for data creation, visualization, and more.\n\n# loading dslabs package\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(here)\n\nhere() starts at C:/Users/vince/OneDrive/Desktop/port-MADA/vincentnguyen-MADA-portfolio"
  },
  {
    "objectID": "data-exercise/data-exercise.qmd.html#seed-setting",
    "href": "data-exercise/data-exercise.qmd.html#seed-setting",
    "title": "Data Exercise",
    "section": "",
    "text": "Since the process is randomized, setting a seed can help improve reproduciblity when creating synthetic data.\n\n# set a seed for reproducibility\nset.seed(123)\n\n# define number of observations\nn_observations &lt;- 100"
  },
  {
    "objectID": "data-exercise/data-exercise.qmd.html#data-creation",
    "href": "data-exercise/data-exercise.qmd.html#data-creation",
    "title": "Data Exercise",
    "section": "",
    "text": "Next, we will begin by creating the data itself. I chose to make a data set on an imaginary disease in an imaginary area. Each district has their region type (urban, suburban, or rural), case count, vaccination rate, population density, attack rate, and level of intervention (none, partial, or full) recorded. While in real life, these variables can heavily affect one , and especially the case count, for this exercise I chose to focus on a few interactions.\nFirst, population density is heavily dependent on the region type. Next, attack rates are affected by population density and intervention level. Lastly, the case count is affected by population density, vaccination rates, and level of intervention. At the end of this block, I created bounds that try to align with what is logically expected for these values.\n\n# create empty data frame with placeholders for variables\n\nsyn_data &lt;- data.frame(\n  DistrictID = numeric(n_observations),\n  RegionType = character(n_observations),\n  CaseCount = numeric(n_observations),\n  VaccinationRate = numeric(n_observations),\n  PopulationDensity = numeric(n_observations),\n  AttackRate = numeric(n_observations),\n  Intervention = character(n_observations)\n)\n\n# Variable 1: District ID\nsyn_data$DistrictID &lt;- 1:n_observations\n\n# Variable 2: Region Type (Categorical variable)\nsyn_data$RegionType &lt;- purrr::map_chr(sample(c(\"Urban\", \"Rural\", \"Suburban\"), n_observations, replace = TRUE), as.character)\n\n\n\n# Variable 4: Vaccination Rate\nsyn_data$VaccinationRate &lt;- runif(n_observations, min = 0.5, max = 1.0)\n\n# Variable 5: Population Density (per km squared)\nsyn_data$PopulationDensity &lt;- with(syn_data, ifelse(\n  RegionType == \"Urban\", rnorm(sum(RegionType == \"Urban\"), mean = 3000, sd = 500),\n  ifelse(RegionType == \"Suburban\", rnorm(sum(RegionType == \"Suburban\"), mean = 1000, sd = 300),\n         rnorm(sum(RegionType == \"Rural\"), mean = 100, sd = 50)\n  )\n))\n\n# Variable 7: Level of Public Health Intervention\nsyn_data$Intervention &lt;- purrr::map_chr(sample(c(\"None\", \"Partial\", \"Full\"), n_observations, replace = TRUE), as.character)\n\n# Variable 6: Attack Rate (Assisted with by ChatGPT)\nsyn_data$AttackRate &lt;- ifelse(\n  syn_data$RegionType == \"Urban\",\n  runif(n_observations, min = 0.05, max = 0.2) * ifelse(syn_data$Intervention == \"Full\", 0.7, 1.2),\n  runif(n_observations, min = 0.01, max = 0.15)\n)\n\n\n# Variable 3: Case Count (Numerical Variable) Assisted with by ChatGPT (moved down here to follow coding flow)\nsyn_data$CaseCount &lt;- round(\n  (200 / (syn_data$VaccinationRate * 2)) * \n  (syn_data$PopulationDensity / 1000) * \n  ifelse(syn_data$Intervention == \"Full\", 0.5, \n         ifelse(syn_data$Intervention == \"Partial\", 0.8, 1.0))\n)\n\n# Ensure logical bounds\nsyn_data$CaseCount &lt;- pmax(syn_data$CaseCount, 0)\nsyn_data$AttackRate &lt;- round(pmax(pmin(syn_data$AttackRate, 1), 0.01), 2)\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 50)  # Density cannot be negative\nsyn_data$VaccinationRate &lt;- round(syn_data$VaccinationRate, 2)  # Round vaccination rates\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 10)"
  },
  {
    "objectID": "data-exercise/data-exercise.qmd.html#data-exploration",
    "href": "data-exercise/data-exercise.qmd.html#data-exploration",
    "title": "Data Exercise",
    "section": "",
    "text": "In this section, I begin by looking at summary statistic for the data. After that, I begin exploring the data visually through various box and scatter plots.\n\n# Summary of data\nsummary(syn_data)\n\n   DistrictID      RegionType          CaseCount     VaccinationRate \n Min.   :  1.00   Length:100         Min.   :  3.0   Min.   :0.5100  \n 1st Qu.: 25.75   Class :character   1st Qu.: 15.0   1st Qu.:0.6375  \n Median : 50.50   Mode  :character   Median :100.0   Median :0.7450  \n Mean   : 50.50                      Mean   :145.1   Mean   :0.7531  \n 3rd Qu.: 75.25                      3rd Qu.:226.2   3rd Qu.:0.8500  \n Max.   :100.00                      Max.   :589.0   Max.   :0.9900  \n PopulationDensity   AttackRate     Intervention      \n Min.   :  50.0    Min.   :0.0100   Length:100        \n 1st Qu.: 123.0    1st Qu.:0.0600   Class :character  \n Median : 987.8    Median :0.0900   Mode  :character  \n Mean   :1380.6    Mean   :0.0973                     \n 3rd Qu.:2599.9    3rd Qu.:0.1300                     \n Max.   :3954.6    Max.   :0.2300                     \n\ndplyr::glimpse(syn_data) \n\nRows: 100\nColumns: 7\n$ DistrictID        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ RegionType        &lt;chr&gt; \"Suburban\", \"Suburban\", \"Suburban\", \"Rural\", \"Suburb…\n$ CaseCount         &lt;dbl&gt; 123, 28, 167, 10, 108, 5, 15, 6, 67, 291, 12, 5, 344…\n$ VaccinationRate   &lt;dbl&gt; 0.68, 0.99, 0.58, 0.55, 0.57, 0.85, 0.81, 0.95, 0.84…\n$ PopulationDensity &lt;dbl&gt; 840.72804, 561.47332, 1206.37503, 56.72436, 613.8908…\n$ AttackRate        &lt;dbl&gt; 0.14, 0.03, 0.10, 0.03, 0.01, 0.08, 0.02, 0.05, 0.07…\n$ Intervention      &lt;chr&gt; \"None\", \"Full\", \"Partial\", \"None\", \"None\", \"Full\", \"…\n\n# Region Case Count\nregion_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = RegionType)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_cases)\n\n\n\n\n\n\n\n# Intervention x Case Count\nintervention_cases &lt;- ggplot(syn_data, aes(x = Intervention, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Intervention Level\",\n                        x = \"Intervention Level\",\n                        y = \"Case Count\")\n\nprint(intervention_cases)\n\n\n\n\n\n\n\n# Region x Intervention x Case Count\nregion_intervention_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type and Intervention level\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_intervention_cases)\n\n\n\n\n\n\n\n# Population Density x Case Count\ndensity_cases &lt;- ggplot(syn_data, aes(x = PopulationDensity, y =CaseCount)) + geom_point() + theme_minimal() +\n    labs(title = \"Case Count by Population Density\",\n         x = \"Population Density (per km squared and Log Scaled)\",\n         y = \"Case Count\") +\n    scale_x_log10()\n\nprint(density_cases)"
  },
  {
    "objectID": "data-exercise/data-exercise.qmd.html#model-creation",
    "href": "data-exercise/data-exercise.qmd.html#model-creation",
    "title": "Data Exercise",
    "section": "",
    "text": "For the final part of this mini-exploration, I chose to conduct three analyses.\nFirst, I did a linear model with the 3 variables, population density, vaccination rate, and intervention. The adjusted R-squared of 0.9313 indicates that, after accounting for the number of predictors, 93.13% of the variance in case count is explained by the variables.\nNext, I looked at whether intervention levels significantly affected the case count of a district by using ANOVA. The p-value of 0.0104 indicates that there is a significant differences among intervention levels.\nLastly, principle component analysis was conducted for exploration purposes. The results indicate that PC1, Population Density, explains 65.1% of the variation seen in the case counts. PC2, vaccination rate, explains 33.12% and PC3, Intervention Level, explains 1.774%. With this in mind, models in the future can consider omitting PC3 because of its small contribution to variance.\n\n# Creation of Linear Model with 3 variables, population density, vaccination rate, and intervention\nlm_model_everything &lt;- lm(CaseCount ~ PopulationDensity + VaccinationRate + Intervention, data = syn_data)\nsummary(lm_model_everything)\n\n\nCall:\nlm(formula = CaseCount ~ PopulationDensity + VaccinationRate + \n    Intervention, data = syn_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-94.268 -20.001  -5.863  23.237 156.904 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.053e+01  2.377e+01   2.126 0.036077 *  \nPopulationDensity    1.057e-01  3.061e-03  34.531  &lt; 2e-16 ***\nVaccinationRate     -1.195e+02  2.974e+01  -4.018 0.000118 ***\nInterventionNone     7.019e+01  1.003e+01   6.999 3.63e-10 ***\nInterventionPartial  4.907e+01  9.107e+00   5.388 5.16e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.43 on 95 degrees of freedom\nMultiple R-squared:  0.934, Adjusted R-squared:  0.9313 \nF-statistic: 336.3 on 4 and 95 DF,  p-value: &lt; 2.2e-16\n\n# Creation of ANOVA to test if intervention levels signficantly affect case count\nanova_model &lt;- aov(CaseCount ~ Intervention, data = syn_data)\nsummary(anova_model)\n\n             Df  Sum Sq Mean Sq F value Pr(&gt;F)  \nIntervention  2  191028   95514   4.785 0.0104 *\nResiduals    97 1936247   19961                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Principle Component Analysis (suggested by ChatGPT) to view which variables explain the variance\npca_model &lt;- prcomp(syn_data[, c(\"PopulationDensity\", \"VaccinationRate\", \"CaseCount\")], center = TRUE, scale. = TRUE)\nsummary(pca_model)\n\nImportance of components:\n                         PC1    PC2     PC3\nStandard deviation     1.398 0.9968 0.23067\nProportion of Variance 0.651 0.3312 0.01774\nCumulative Proportion  0.651 0.9823 1.00000"
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data Exercise",
    "section": "",
    "text": "First, we will start with loading some necessary packages for data creation, visualization, and more.\n\n# loading dslabs package\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.3.3\n\n\nhere() starts at C:/Users/vince/OneDrive/Desktop/port-MADA/vincentnguyen-MADA-portfolio\n\n\n\n\n\nSince the process is randomized, setting a seed can help improve reproduciblity when creating synthetic data.\n\n# set a seed for reproducibility\nset.seed(123)\n\n# define number of observations\nn_observations &lt;- 100\n\n\n\n\nNext, we will begin by creating the data itself. I chose to make a data set on an imaginary disease in an imaginary area. Each district has their region type (urban, suburban, or rural), case count, vaccination rate, population density, attack rate, and level of intervention (none, partial, or full) recorded. While in real life, these variables can heavily affect one , and especially the case count, for this exercise I chose to focus on a few interactions.\nFirst, population density is heavily dependent on the region type. Next, attack rates are affected by population density and intervention level. Lastly, the case count is affected by population density, vaccination rates, and level of intervention. At the end of this block, I created bounds that try to align with what is logically expected for these values.\n\n# create empty data frame with placeholders for variables\n\nsyn_data &lt;- data.frame(\n  DistrictID = numeric(n_observations),\n  RegionType = character(n_observations),\n  CaseCount = numeric(n_observations),\n  VaccinationRate = numeric(n_observations),\n  PopulationDensity = numeric(n_observations),\n  AttackRate = numeric(n_observations),\n  Intervention = character(n_observations)\n)\n\n# Variable 1: District ID\nsyn_data$DistrictID &lt;- 1:n_observations\n\n# Variable 2: Region Type (Categorical variable)\nsyn_data$RegionType &lt;- purrr::map_chr(sample(c(\"Urban\", \"Rural\", \"Suburban\"), n_observations, replace = TRUE), as.character)\n\n\n\n# Variable 4: Vaccination Rate\nsyn_data$VaccinationRate &lt;- runif(n_observations, min = 0.5, max = 1.0)\n\n# Variable 5: Population Density (per km squared)\nsyn_data$PopulationDensity &lt;- with(syn_data, ifelse(\n  RegionType == \"Urban\", rnorm(sum(RegionType == \"Urban\"), mean = 3000, sd = 500),\n  ifelse(RegionType == \"Suburban\", rnorm(sum(RegionType == \"Suburban\"), mean = 1000, sd = 300),\n         rnorm(sum(RegionType == \"Rural\"), mean = 100, sd = 50)\n  )\n))\n\n# Variable 7: Level of Public Health Intervention\nsyn_data$Intervention &lt;- purrr::map_chr(sample(c(\"None\", \"Partial\", \"Full\"), n_observations, replace = TRUE), as.character)\n\n# Variable 6: Attack Rate (Assisted with by ChatGPT)\nsyn_data$AttackRate &lt;- ifelse(\n  syn_data$RegionType == \"Urban\",\n  runif(n_observations, min = 0.05, max = 0.2) * ifelse(syn_data$Intervention == \"Full\", 0.7, 1.2),\n  runif(n_observations, min = 0.01, max = 0.15)\n)\n\n\n# Variable 3: Case Count (Numerical Variable) Assisted with by ChatGPT (moved down here to follow coding flow)\nsyn_data$CaseCount &lt;- round(\n  (200 / (syn_data$VaccinationRate * 2)) * \n  (syn_data$PopulationDensity / 1000) * \n  ifelse(syn_data$Intervention == \"Full\", 0.5, \n         ifelse(syn_data$Intervention == \"Partial\", 0.8, 1.0))\n)\n\n# Ensure logical bounds\nsyn_data$CaseCount &lt;- pmax(syn_data$CaseCount, 0)\nsyn_data$AttackRate &lt;- round(pmax(pmin(syn_data$AttackRate, 1), 0.01), 2)\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 50)  # Density cannot be negative\nsyn_data$VaccinationRate &lt;- round(syn_data$VaccinationRate, 2)  # Round vaccination rates\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 10)\n\n\n\n\nIn this section, I begin by looking at summary statistic for the data. After that, I begin exploring the data visually through various box and scatter plots.\n\n# Summary of data\nsummary(syn_data)\n\n   DistrictID      RegionType          CaseCount     VaccinationRate \n Min.   :  1.00   Length:100         Min.   :  3.0   Min.   :0.5100  \n 1st Qu.: 25.75   Class :character   1st Qu.: 15.0   1st Qu.:0.6375  \n Median : 50.50   Mode  :character   Median :100.0   Median :0.7450  \n Mean   : 50.50                      Mean   :145.1   Mean   :0.7531  \n 3rd Qu.: 75.25                      3rd Qu.:226.2   3rd Qu.:0.8500  \n Max.   :100.00                      Max.   :589.0   Max.   :0.9900  \n PopulationDensity   AttackRate     Intervention      \n Min.   :  50.0    Min.   :0.0100   Length:100        \n 1st Qu.: 123.0    1st Qu.:0.0600   Class :character  \n Median : 987.8    Median :0.0900   Mode  :character  \n Mean   :1380.6    Mean   :0.0973                     \n 3rd Qu.:2599.9    3rd Qu.:0.1300                     \n Max.   :3954.6    Max.   :0.2300                     \n\ndplyr::glimpse(syn_data) \n\nRows: 100\nColumns: 7\n$ DistrictID        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ RegionType        &lt;chr&gt; \"Suburban\", \"Suburban\", \"Suburban\", \"Rural\", \"Suburb…\n$ CaseCount         &lt;dbl&gt; 123, 28, 167, 10, 108, 5, 15, 6, 67, 291, 12, 5, 344…\n$ VaccinationRate   &lt;dbl&gt; 0.68, 0.99, 0.58, 0.55, 0.57, 0.85, 0.81, 0.95, 0.84…\n$ PopulationDensity &lt;dbl&gt; 840.72804, 561.47332, 1206.37503, 56.72436, 613.8908…\n$ AttackRate        &lt;dbl&gt; 0.14, 0.03, 0.10, 0.03, 0.01, 0.08, 0.02, 0.05, 0.07…\n$ Intervention      &lt;chr&gt; \"None\", \"Full\", \"Partial\", \"None\", \"None\", \"Full\", \"…\n\n# Region Case Count\nregion_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = RegionType)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_cases)\n\n\n\n\n\n\n\n# Intervention x Case Count\nintervention_cases &lt;- ggplot(syn_data, aes(x = Intervention, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Intervention Level\",\n                        x = \"Intervention Level\",\n                        y = \"Case Count\")\n\nprint(intervention_cases)\n\n\n\n\n\n\n\n# Region x Intervention x Case Count\nregion_intervention_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type and Intervention level\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_intervention_cases)\n\n\n\n\n\n\n\n# Population Density x Case Count\ndensity_cases &lt;- ggplot(syn_data, aes(x = PopulationDensity, y =CaseCount)) + geom_point() + theme_minimal() +\n    labs(title = \"Case Count by Population Density\",\n         x = \"Population Density (per km squared and Log Scaled)\",\n         y = \"Case Count\") +\n    scale_x_log10()\n\nprint(density_cases)\n\n\n\n\n\n\n\n\n\n\n\nFor the final part of this mini-exploration, I chose to conduct three analyses.\nFirst, I did a linear model with the 3 variables, population density, vaccination rate, and intervention. The adjusted R-squared of 0.9313 indicates that, after accounting for the number of predictors, 93.13% of the variance in case count is explained by the variables.\nNext, I looked at whether intervention levels significantly affected the case count of a district by using ANOVA. The p-value of 0.0104 indicates that there is a significant differences among intervention levels.\nLastly, principle component analysis was conducted for exploration purposes. The results indicate that PC1, Population Density, explains 65.1% of the variation seen in the case counts. PC2, vaccination rate, explains 33.12% and PC3, Intervention Level, explains 1.774%. With this in mind, models in the future can consider omitting PC3 because of its small contribution to variance.\n\n# Creation of Linear Model with 3 variables, population density, vaccination rate, and intervention\nlm_model_everything &lt;- lm(CaseCount ~ PopulationDensity + VaccinationRate + Intervention, data = syn_data)\nsummary(lm_model_everything)\n\n\nCall:\nlm(formula = CaseCount ~ PopulationDensity + VaccinationRate + \n    Intervention, data = syn_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-94.268 -20.001  -5.863  23.237 156.904 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.053e+01  2.377e+01   2.126 0.036077 *  \nPopulationDensity    1.057e-01  3.061e-03  34.531  &lt; 2e-16 ***\nVaccinationRate     -1.195e+02  2.974e+01  -4.018 0.000118 ***\nInterventionNone     7.019e+01  1.003e+01   6.999 3.63e-10 ***\nInterventionPartial  4.907e+01  9.107e+00   5.388 5.16e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.43 on 95 degrees of freedom\nMultiple R-squared:  0.934, Adjusted R-squared:  0.9313 \nF-statistic: 336.3 on 4 and 95 DF,  p-value: &lt; 2.2e-16\n\n# Creation of ANOVA to test if intervention levels signficantly affect case count\nanova_model &lt;- aov(CaseCount ~ Intervention, data = syn_data)\nsummary(anova_model)\n\n             Df  Sum Sq Mean Sq F value Pr(&gt;F)  \nIntervention  2  191028   95514   4.785 0.0104 *\nResiduals    97 1936247   19961                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Principle Component Analysis (suggested by ChatGPT) to view which variables explain the variance\npca_model &lt;- prcomp(syn_data[, c(\"PopulationDensity\", \"VaccinationRate\", \"CaseCount\")], center = TRUE, scale. = TRUE)\nsummary(pca_model)\n\nImportance of components:\n                         PC1    PC2     PC3\nStandard deviation     1.398 0.9968 0.23067\nProportion of Variance 0.651 0.3312 0.01774\nCumulative Proportion  0.651 0.9823 1.00000"
  },
  {
    "objectID": "data-exercise/data-exercise.html#package-loading",
    "href": "data-exercise/data-exercise.html#package-loading",
    "title": "Data Exercise",
    "section": "",
    "text": "First, we will start with loading some necessary packages for data creation, visualization, and more.\n\n# loading dslabs package\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.3.3\n\n\nhere() starts at C:/Users/vince/OneDrive/Desktop/port-MADA/vincentnguyen-MADA-portfolio"
  },
  {
    "objectID": "data-exercise/data-exercise.html#seed-setting",
    "href": "data-exercise/data-exercise.html#seed-setting",
    "title": "Data Exercise",
    "section": "",
    "text": "Since the process is randomized, setting a seed can help improve reproduciblity when creating synthetic data.\n\n# set a seed for reproducibility\nset.seed(123)\n\n# define number of observations\nn_observations &lt;- 100"
  },
  {
    "objectID": "data-exercise/data-exercise.html#data-creation",
    "href": "data-exercise/data-exercise.html#data-creation",
    "title": "Data Exercise",
    "section": "",
    "text": "Next, we will begin by creating the data itself. I chose to make a data set on an imaginary disease in an imaginary area. Each district has their region type (urban, suburban, or rural), case count, vaccination rate, population density, attack rate, and level of intervention (none, partial, or full) recorded. While in real life, these variables can heavily affect one , and especially the case count, for this exercise I chose to focus on a few interactions.\nFirst, population density is heavily dependent on the region type. Next, attack rates are affected by population density and intervention level. Lastly, the case count is affected by population density, vaccination rates, and level of intervention. At the end of this block, I created bounds that try to align with what is logically expected for these values.\n\n# create empty data frame with placeholders for variables\n\nsyn_data &lt;- data.frame(\n  DistrictID = numeric(n_observations),\n  RegionType = character(n_observations),\n  CaseCount = numeric(n_observations),\n  VaccinationRate = numeric(n_observations),\n  PopulationDensity = numeric(n_observations),\n  AttackRate = numeric(n_observations),\n  Intervention = character(n_observations)\n)\n\n# Variable 1: District ID\nsyn_data$DistrictID &lt;- 1:n_observations\n\n# Variable 2: Region Type (Categorical variable)\nsyn_data$RegionType &lt;- purrr::map_chr(sample(c(\"Urban\", \"Rural\", \"Suburban\"), n_observations, replace = TRUE), as.character)\n\n\n\n# Variable 4: Vaccination Rate\nsyn_data$VaccinationRate &lt;- runif(n_observations, min = 0.5, max = 1.0)\n\n# Variable 5: Population Density (per km squared)\nsyn_data$PopulationDensity &lt;- with(syn_data, ifelse(\n  RegionType == \"Urban\", rnorm(sum(RegionType == \"Urban\"), mean = 3000, sd = 500),\n  ifelse(RegionType == \"Suburban\", rnorm(sum(RegionType == \"Suburban\"), mean = 1000, sd = 300),\n         rnorm(sum(RegionType == \"Rural\"), mean = 100, sd = 50)\n  )\n))\n\n# Variable 7: Level of Public Health Intervention\nsyn_data$Intervention &lt;- purrr::map_chr(sample(c(\"None\", \"Partial\", \"Full\"), n_observations, replace = TRUE), as.character)\n\n# Variable 6: Attack Rate (Assisted with by ChatGPT)\nsyn_data$AttackRate &lt;- ifelse(\n  syn_data$RegionType == \"Urban\",\n  runif(n_observations, min = 0.05, max = 0.2) * ifelse(syn_data$Intervention == \"Full\", 0.7, 1.2),\n  runif(n_observations, min = 0.01, max = 0.15)\n)\n\n\n# Variable 3: Case Count (Numerical Variable) Assisted with by ChatGPT (moved down here to follow coding flow)\nsyn_data$CaseCount &lt;- round(\n  (200 / (syn_data$VaccinationRate * 2)) * \n  (syn_data$PopulationDensity / 1000) * \n  ifelse(syn_data$Intervention == \"Full\", 0.5, \n         ifelse(syn_data$Intervention == \"Partial\", 0.8, 1.0))\n)\n\n# Ensure logical bounds\nsyn_data$CaseCount &lt;- pmax(syn_data$CaseCount, 0)\nsyn_data$AttackRate &lt;- round(pmax(pmin(syn_data$AttackRate, 1), 0.01), 2)\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 50)  # Density cannot be negative\nsyn_data$VaccinationRate &lt;- round(syn_data$VaccinationRate, 2)  # Round vaccination rates\nsyn_data$PopulationDensity &lt;- pmax(syn_data$PopulationDensity, 10)"
  },
  {
    "objectID": "data-exercise/data-exercise.html#data-exploration",
    "href": "data-exercise/data-exercise.html#data-exploration",
    "title": "Data Exercise",
    "section": "",
    "text": "In this section, I begin by looking at summary statistic for the data. After that, I begin exploring the data visually through various box and scatter plots.\n\n# Summary of data\nsummary(syn_data)\n\n   DistrictID      RegionType          CaseCount     VaccinationRate \n Min.   :  1.00   Length:100         Min.   :  3.0   Min.   :0.5100  \n 1st Qu.: 25.75   Class :character   1st Qu.: 15.0   1st Qu.:0.6375  \n Median : 50.50   Mode  :character   Median :100.0   Median :0.7450  \n Mean   : 50.50                      Mean   :145.1   Mean   :0.7531  \n 3rd Qu.: 75.25                      3rd Qu.:226.2   3rd Qu.:0.8500  \n Max.   :100.00                      Max.   :589.0   Max.   :0.9900  \n PopulationDensity   AttackRate     Intervention      \n Min.   :  50.0    Min.   :0.0100   Length:100        \n 1st Qu.: 123.0    1st Qu.:0.0600   Class :character  \n Median : 987.8    Median :0.0900   Mode  :character  \n Mean   :1380.6    Mean   :0.0973                     \n 3rd Qu.:2599.9    3rd Qu.:0.1300                     \n Max.   :3954.6    Max.   :0.2300                     \n\ndplyr::glimpse(syn_data) \n\nRows: 100\nColumns: 7\n$ DistrictID        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ RegionType        &lt;chr&gt; \"Suburban\", \"Suburban\", \"Suburban\", \"Rural\", \"Suburb…\n$ CaseCount         &lt;dbl&gt; 123, 28, 167, 10, 108, 5, 15, 6, 67, 291, 12, 5, 344…\n$ VaccinationRate   &lt;dbl&gt; 0.68, 0.99, 0.58, 0.55, 0.57, 0.85, 0.81, 0.95, 0.84…\n$ PopulationDensity &lt;dbl&gt; 840.72804, 561.47332, 1206.37503, 56.72436, 613.8908…\n$ AttackRate        &lt;dbl&gt; 0.14, 0.03, 0.10, 0.03, 0.01, 0.08, 0.02, 0.05, 0.07…\n$ Intervention      &lt;chr&gt; \"None\", \"Full\", \"Partial\", \"None\", \"None\", \"Full\", \"…\n\n# Region Case Count\nregion_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = RegionType)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_cases)\n\n\n\n\n\n\n\n# Intervention x Case Count\nintervention_cases &lt;- ggplot(syn_data, aes(x = Intervention, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Intervention Level\",\n                        x = \"Intervention Level\",\n                        y = \"Case Count\")\n\nprint(intervention_cases)\n\n\n\n\n\n\n\n# Region x Intervention x Case Count\nregion_intervention_cases &lt;- ggplot(syn_data, aes(x = RegionType, y = CaseCount, fill = Intervention)) + geom_boxplot() + theme_minimal() + labs(title = \"Case Count by Region Type and Intervention level\",\n                        x = \"Region Type\",\n                        y = \"Case Count\")\n\nprint(region_intervention_cases)\n\n\n\n\n\n\n\n# Population Density x Case Count\ndensity_cases &lt;- ggplot(syn_data, aes(x = PopulationDensity, y =CaseCount)) + geom_point() + theme_minimal() +\n    labs(title = \"Case Count by Population Density\",\n         x = \"Population Density (per km squared and Log Scaled)\",\n         y = \"Case Count\") +\n    scale_x_log10()\n\nprint(density_cases)"
  },
  {
    "objectID": "data-exercise/data-exercise.html#model-creation",
    "href": "data-exercise/data-exercise.html#model-creation",
    "title": "Data Exercise",
    "section": "",
    "text": "For the final part of this mini-exploration, I chose to conduct three analyses.\nFirst, I did a linear model with the 3 variables, population density, vaccination rate, and intervention. The adjusted R-squared of 0.9313 indicates that, after accounting for the number of predictors, 93.13% of the variance in case count is explained by the variables.\nNext, I looked at whether intervention levels significantly affected the case count of a district by using ANOVA. The p-value of 0.0104 indicates that there is a significant differences among intervention levels.\nLastly, principle component analysis was conducted for exploration purposes. The results indicate that PC1, Population Density, explains 65.1% of the variation seen in the case counts. PC2, vaccination rate, explains 33.12% and PC3, Intervention Level, explains 1.774%. With this in mind, models in the future can consider omitting PC3 because of its small contribution to variance.\n\n# Creation of Linear Model with 3 variables, population density, vaccination rate, and intervention\nlm_model_everything &lt;- lm(CaseCount ~ PopulationDensity + VaccinationRate + Intervention, data = syn_data)\nsummary(lm_model_everything)\n\n\nCall:\nlm(formula = CaseCount ~ PopulationDensity + VaccinationRate + \n    Intervention, data = syn_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-94.268 -20.001  -5.863  23.237 156.904 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.053e+01  2.377e+01   2.126 0.036077 *  \nPopulationDensity    1.057e-01  3.061e-03  34.531  &lt; 2e-16 ***\nVaccinationRate     -1.195e+02  2.974e+01  -4.018 0.000118 ***\nInterventionNone     7.019e+01  1.003e+01   6.999 3.63e-10 ***\nInterventionPartial  4.907e+01  9.107e+00   5.388 5.16e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.43 on 95 degrees of freedom\nMultiple R-squared:  0.934, Adjusted R-squared:  0.9313 \nF-statistic: 336.3 on 4 and 95 DF,  p-value: &lt; 2.2e-16\n\n# Creation of ANOVA to test if intervention levels signficantly affect case count\nanova_model &lt;- aov(CaseCount ~ Intervention, data = syn_data)\nsummary(anova_model)\n\n             Df  Sum Sq Mean Sq F value Pr(&gt;F)  \nIntervention  2  191028   95514   4.785 0.0104 *\nResiduals    97 1936247   19961                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Principle Component Analysis (suggested by ChatGPT) to view which variables explain the variance\npca_model &lt;- prcomp(syn_data[, c(\"PopulationDensity\", \"VaccinationRate\", \"CaseCount\")], center = TRUE, scale. = TRUE)\nsummary(pca_model)\n\nImportance of components:\n                         PC1    PC2     PC3\nStandard deviation     1.398 0.9968 0.23067\nProportion of Variance 0.651 0.3312 0.01774\nCumulative Proportion  0.651 0.9823 1.00000"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html",
    "href": "cdcdata-exercise/cdcdata-exercise.html",
    "title": "CDC Data Exercise",
    "section": "",
    "text": "First, we will start with loading some necessary packages for data creation, visualization, and more.\n\n# loading dslabs package\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.3.3\n\n\nhere() starts at C:/Users/vince/OneDrive/Desktop/port-MADA/vincentnguyen-MADA-portfolio\n\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.3.3\n\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.3.3\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\n\n\nThe data set is titled, “Weekly Provisional Counts of Deaths by State and Select Causes, 2020-2023”. The data set contains 10476 observations of 35 variables. It covers counts of death by nationally or by state. Additionally, it includes causes of death and more.\n\n# Import dataset\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"cdcdata-exercise\", \"Weekly_Provisional_Counts_of_Deaths_by_State_and_Select_Causes__2020-2023_20250204.csv\")\ndata &lt;- read.csv(data_location)%&gt;%\n  clean_names()\n\n# filterd for only the US (no states) and then also removed some diseases not of interest\n# also rename the columns because they are formatted weird\ndata_filtered &lt;- data %&gt;%\n  filter(jurisdiction_of_occurrence == \"United States\") %&gt;%\n  select(1:7, 9:10, 12, 17) %&gt;%\n  rename(\n    cancer_count = malignant_neoplasms_c00_c97,\n    diabetes_count = diabetes_mellitus_e10_e14,\n    influenza_pneumonia_count = influenza_and_pneumonia_j09_j18,\n    heart_disease_count = diseases_of_heart_i00_i09_i11_i13_i20_i51\n  )\n\n\n\n\nCreation of summary statistics for the entire data set and for diseases of interest.\n\n# summary statistics of all causes of death\nsummary(data_filtered)\n\n  data_as_of        jurisdiction_of_occurrence   mmwr_year      mmwr_week    \n Length:194         Length:194                 Min.   :2020   Min.   : 1.00  \n Class :character   Class :character           1st Qu.:2020   1st Qu.:13.00  \n Mode  :character   Mode  :character           Median :2021   Median :25.00  \n                                               Mean   :2021   Mean   :25.21  \n                                               3rd Qu.:2022   3rd Qu.:37.00  \n                                               Max.   :2023   Max.   :53.00  \n week_ending_date     all_cause     natural_cause    cancer_count  \n Length:194         Min.   :37874   Min.   :37824   Min.   : 8675  \n Class :character   1st Qu.:58434   1st Qu.:52449   1st Qu.:11484  \n Mode  :character   Median :60628   Median :54836   Median :11618  \n                    Mean   :63459   Mean   :57802   Mean   :11599  \n                    3rd Qu.:67061   3rd Qu.:61131   3rd Qu.:11781  \n                    Max.   :87415   Max.   :81622   Max.   :12284  \n diabetes_count influenza_pneumonia_count heart_disease_count\n Min.   :1115   Min.   : 495.0            Min.   : 8034      \n 1st Qu.:1800   1st Qu.: 715.2            1st Qu.:12621      \n Median :1895   Median : 792.0            Median :13104      \n Mean   :1923   Mean   : 896.4            Mean   :13255      \n 3rd Qu.:2014   3rd Qu.: 944.5            3rd Qu.:13727      \n Max.   :2601   Max.   :1916.0            Max.   :16538      \n\n# mmean / sd of cancer deaths\nmean(data_filtered$cancer_count)\n\n[1] 11598.83\n\nsd(data_filtered$cancer_count)\n\n[1] 328.8402\n\n# mean / sd of diabetes\nmean(data_filtered$diabetes_count)\n\n[1] 1922.701\n\nsd(data_filtered$diabetes_count)\n\n[1] 212.36\n\n# mean / sd of heart disease\nmean(data_filtered$heart_disease_count)\n\n[1] 13254.74\n\nsd(data_filtered$heart_disease_count)\n\n[1] 1078.617\n\n# mean / sd of influenza and pneumonia\nmean(data_filtered$influenza_pneumonia_count)\n\n[1] 896.4278\n\nsd(data_filtered$influenza_pneumonia_count)\n\n[1] 296.1237\n\n\n\n\n\nCreation of graphs to visualize the distribution of death count cases on a MMWR week-to-week basis. Surprisingly, they look almost normal with some skewing on some of the graphs.\n\n# Distribution graph of cancer deaths\ncancer_graph &lt;- ggplot(data_filtered, aes(x = cancer_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Cancer Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Cancer Death Counts\"\n  )\n\nprint(cancer_graph)\n\n\n\n\n\n\n\n# Distribution graph of diabetes deaths\ndiabetes_graph &lt;- ggplot(data_filtered, aes(x = diabetes_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Diabetes Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Diabetes Death Counts\"\n  )\n\nprint(diabetes_graph)\n\n\n\n\n\n\n\n# Distribution graph of heart disease deaths\nheart_disease_graph &lt;- ggplot(data_filtered, aes(x = heart_disease_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Heart Disease Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Heart Disease Death Counts\"\n  )\n\nprint(heart_disease_graph)\n\n\n\n\n\n\n\n# Distribution graph of influenza/pneumonia deaths\ninfluenza_pneumonia_graph &lt;- ggplot(data_filtered, aes(x = influenza_pneumonia_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Influenza/Pneumonia Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Influenza/Pneumonia Death Counts\"\n  )\n\nprint(influenza_pneumonia_graph)\n\n\n\n\n\n\n\n\n\n\n\nThis section was contributed by Connor Norris.\n\n#Additional exploratory analysis\n\n#Mean and SD of all-cause mortality\npaste(\"Mean of All-Cause Mortality:\", mean(data_filtered$all_cause))\n\n[1] \"Mean of All-Cause Mortality: 63459.4175257732\"\n\npaste(\"SD of All-Cause Mortality:\", sd(data_filtered$all_cause))\n\n[1] \"SD of All-Cause Mortality: 8007.63952760385\"\n\n#Histogram of all-cause mortality\nggplot(data_filtered, aes(x = all_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"All Cause Mortality Count\",\n    y = \"Frequency\",\n    title = \"Distribution of All Cause Mortality\"\n  )\n\n\n\n\n\n\n\n#Mean and SD of natural cause mortality\npaste(\"Mean of Natural Cause Mortality:\", mean(data_filtered$natural_cause))\n\n[1] \"Mean of Natural Cause Mortality: 57802.3453608247\"\n\npaste(\"SD of Natural Cause Mortality:\", sd(data_filtered$natural_cause))\n\n[1] \"SD of Natural Cause Mortality: 7776.10692380645\"\n\n#Histogram of natural cause mortality\nggplot(data_filtered, aes(x = natural_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Natural Cause Mortality Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Natural Cause Mortality\"\n  )\n\n\n\n\n\n\n\n\n\n#Synthetic data creation\nobs &lt;- nrow(data_filtered) #Number of observations\n\nsyn &lt;- data.frame(\n  \n  #Set non-mortality data to match the previous dataset\n  data_as_of = rep(as.Date('02/07/25', format = \"%m/%d/%y\"), obs),\n  jurisdiction_of_occurance = rep('United States', obs),\n  mmwr_year = c(rep(2020, nrow(filter(data_filtered, mmwr_year == 2020))),\n                rep(2021, nrow(filter(data_filtered, mmwr_year == 2021))),\n                rep(2022, nrow(filter(data_filtered, mmwr_year == 2022))),\n                rep(2023, nrow(filter(data_filtered, mmwr_year == 2023)))),\n  mmwr_week = c(1:nrow(filter(data_filtered, mmwr_year == 2020)),\n                1:nrow(filter(data_filtered, mmwr_year == 2021)),\n                1:nrow(filter(data_filtered, mmwr_year == 2022)),\n                1:nrow(filter(data_filtered, mmwr_year == 2023))),\n  \n  #Simulate the mortality variables using normal distributions\n  all_cause = rnorm(obs, mean = mean(data_filtered$all_cause), sd = sd(data_filtered$all_cause)),\n  natural_cause = rnorm(obs, mean = mean(data_filtered$natural_cause), sd = sd(data_filtered$natural_cause)),\n  cancer_count = rnorm(obs, mean = mean(data_filtered$cancer_count), sd = sd(data_filtered$cancer_count)),\n  diabetes_count = rnorm(obs, mean = mean(data_filtered$diabetes_count), sd = sd(data_filtered$diabetes_count)),\n  influenza_pneumonia_count = rnorm(obs, mean = mean(data_filtered$influenza_pneumonia_count), sd = sd(data_filtered$influenza_pneumonia_count)),\n  heart_disease_count = rnorm(obs, mean = mean(data_filtered$heart_disease_count), sd = sd(data_filtered$heart_disease_count))\n)\n\nAfter synthesizing the new dataset, I will plot histograms of each of the mortality variables and compare to the original dataset.\n\n#Plotting distributions\n#All-cause mortality\nggplot(syn, aes(x = all_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"All Cause Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of All Cause Mortality\"\n  )\n\n\n\n\n\n\n\n#Natural cause mortality\nggplot(syn, aes(x = natural_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Natural Cause Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Natural Cause Mortality\"\n  )\n\n\n\n\n\n\n\n#Cancer mortality\nggplot(syn, aes(x = cancer_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Cancer Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Cancer Mortality\"\n  )\n\n\n\n\n\n\n\n#Diabetes mortality\nggplot(syn, aes(x = diabetes_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Diabetes Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Diabetes Mortality\"\n  )\n\n\n\n\n\n\n\n#Influenza and pneumonia mortality\nggplot(syn, aes(x = influenza_pneumonia_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Influenza and Pneumonia Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Influenza and Pneumonia Mortality\"\n  )\n\n\n\n\n\n\n\n#Heart disease mortality\nggplot(syn, aes(x = heart_disease_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Heart Disease Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Heart Disease Mortality\"\n  )\n\n\n\n\n\n\n\n\nThese distributions match the original data well in terms of their range of values and where the mean lies. However, there are some variations in the shape of the data. While the mortality data in the original dataset was largely normal, some outliers that were present in the original data were gave some of the distributions a slight skew. The simulations here incorporated those outlier values in the main distrubution, so the shape of the distributions differed in the synthetic data."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#package-loading",
    "href": "cdcdata-exercise/cdcdata-exercise.html#package-loading",
    "title": "CDC Data Exercise",
    "section": "",
    "text": "First, we will start with loading some necessary packages for data creation, visualization, and more.\n\n# loading dslabs package\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.3.3\n\n\nhere() starts at C:/Users/vince/OneDrive/Desktop/port-MADA/vincentnguyen-MADA-portfolio\n\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.3.3\n\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.3.3\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#data-set",
    "href": "cdcdata-exercise/cdcdata-exercise.html#data-set",
    "title": "CDC Data Exercise",
    "section": "",
    "text": "The data set is titled, “Weekly Provisional Counts of Deaths by State and Select Causes, 2020-2023”. The data set contains 10476 observations of 35 variables. It covers counts of death by nationally or by state. Additionally, it includes causes of death and more.\n\n# Import dataset\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"cdcdata-exercise\", \"Weekly_Provisional_Counts_of_Deaths_by_State_and_Select_Causes__2020-2023_20250204.csv\")\ndata &lt;- read.csv(data_location)%&gt;%\n  clean_names()\n\n# filterd for only the US (no states) and then also removed some diseases not of interest\n# also rename the columns because they are formatted weird\ndata_filtered &lt;- data %&gt;%\n  filter(jurisdiction_of_occurrence == \"United States\") %&gt;%\n  select(1:7, 9:10, 12, 17) %&gt;%\n  rename(\n    cancer_count = malignant_neoplasms_c00_c97,\n    diabetes_count = diabetes_mellitus_e10_e14,\n    influenza_pneumonia_count = influenza_and_pneumonia_j09_j18,\n    heart_disease_count = diseases_of_heart_i00_i09_i11_i13_i20_i51\n  )"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#summary-stats",
    "href": "cdcdata-exercise/cdcdata-exercise.html#summary-stats",
    "title": "CDC Data Exercise",
    "section": "",
    "text": "Creation of summary statistics for the entire data set and for diseases of interest.\n\n# summary statistics of all causes of death\nsummary(data_filtered)\n\n  data_as_of        jurisdiction_of_occurrence   mmwr_year      mmwr_week    \n Length:194         Length:194                 Min.   :2020   Min.   : 1.00  \n Class :character   Class :character           1st Qu.:2020   1st Qu.:13.00  \n Mode  :character   Mode  :character           Median :2021   Median :25.00  \n                                               Mean   :2021   Mean   :25.21  \n                                               3rd Qu.:2022   3rd Qu.:37.00  \n                                               Max.   :2023   Max.   :53.00  \n week_ending_date     all_cause     natural_cause    cancer_count  \n Length:194         Min.   :37874   Min.   :37824   Min.   : 8675  \n Class :character   1st Qu.:58434   1st Qu.:52449   1st Qu.:11484  \n Mode  :character   Median :60628   Median :54836   Median :11618  \n                    Mean   :63459   Mean   :57802   Mean   :11599  \n                    3rd Qu.:67061   3rd Qu.:61131   3rd Qu.:11781  \n                    Max.   :87415   Max.   :81622   Max.   :12284  \n diabetes_count influenza_pneumonia_count heart_disease_count\n Min.   :1115   Min.   : 495.0            Min.   : 8034      \n 1st Qu.:1800   1st Qu.: 715.2            1st Qu.:12621      \n Median :1895   Median : 792.0            Median :13104      \n Mean   :1923   Mean   : 896.4            Mean   :13255      \n 3rd Qu.:2014   3rd Qu.: 944.5            3rd Qu.:13727      \n Max.   :2601   Max.   :1916.0            Max.   :16538      \n\n# mmean / sd of cancer deaths\nmean(data_filtered$cancer_count)\n\n[1] 11598.83\n\nsd(data_filtered$cancer_count)\n\n[1] 328.8402\n\n# mean / sd of diabetes\nmean(data_filtered$diabetes_count)\n\n[1] 1922.701\n\nsd(data_filtered$diabetes_count)\n\n[1] 212.36\n\n# mean / sd of heart disease\nmean(data_filtered$heart_disease_count)\n\n[1] 13254.74\n\nsd(data_filtered$heart_disease_count)\n\n[1] 1078.617\n\n# mean / sd of influenza and pneumonia\nmean(data_filtered$influenza_pneumonia_count)\n\n[1] 896.4278\n\nsd(data_filtered$influenza_pneumonia_count)\n\n[1] 296.1237"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#graphs-for-distributions",
    "href": "cdcdata-exercise/cdcdata-exercise.html#graphs-for-distributions",
    "title": "CDC Data Exercise",
    "section": "",
    "text": "Creation of graphs to visualize the distribution of death count cases on a MMWR week-to-week basis. Surprisingly, they look almost normal with some skewing on some of the graphs.\n\n# Distribution graph of cancer deaths\ncancer_graph &lt;- ggplot(data_filtered, aes(x = cancer_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Cancer Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Cancer Death Counts\"\n  )\n\nprint(cancer_graph)\n\n\n\n\n\n\n\n# Distribution graph of diabetes deaths\ndiabetes_graph &lt;- ggplot(data_filtered, aes(x = diabetes_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Diabetes Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Diabetes Death Counts\"\n  )\n\nprint(diabetes_graph)\n\n\n\n\n\n\n\n# Distribution graph of heart disease deaths\nheart_disease_graph &lt;- ggplot(data_filtered, aes(x = heart_disease_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Heart Disease Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Heart Disease Death Counts\"\n  )\n\nprint(heart_disease_graph)\n\n\n\n\n\n\n\n# Distribution graph of influenza/pneumonia deaths\ninfluenza_pneumonia_graph &lt;- ggplot(data_filtered, aes(x = influenza_pneumonia_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Influenza/Pneumonia Death Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Influenza/Pneumonia Death Counts\"\n  )\n\nprint(influenza_pneumonia_graph)"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#synthesizing-new-data",
    "href": "cdcdata-exercise/cdcdata-exercise.html#synthesizing-new-data",
    "title": "CDC Data Exercise",
    "section": "",
    "text": "This section was contributed by Connor Norris.\n\n#Additional exploratory analysis\n\n#Mean and SD of all-cause mortality\npaste(\"Mean of All-Cause Mortality:\", mean(data_filtered$all_cause))\n\n[1] \"Mean of All-Cause Mortality: 63459.4175257732\"\n\npaste(\"SD of All-Cause Mortality:\", sd(data_filtered$all_cause))\n\n[1] \"SD of All-Cause Mortality: 8007.63952760385\"\n\n#Histogram of all-cause mortality\nggplot(data_filtered, aes(x = all_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"All Cause Mortality Count\",\n    y = \"Frequency\",\n    title = \"Distribution of All Cause Mortality\"\n  )\n\n\n\n\n\n\n\n#Mean and SD of natural cause mortality\npaste(\"Mean of Natural Cause Mortality:\", mean(data_filtered$natural_cause))\n\n[1] \"Mean of Natural Cause Mortality: 57802.3453608247\"\n\npaste(\"SD of Natural Cause Mortality:\", sd(data_filtered$natural_cause))\n\n[1] \"SD of Natural Cause Mortality: 7776.10692380645\"\n\n#Histogram of natural cause mortality\nggplot(data_filtered, aes(x = natural_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Natural Cause Mortality Count\",\n    y = \"Frequency\",\n    title = \"Distribution of Natural Cause Mortality\"\n  )\n\n\n\n\n\n\n\n\n\n#Synthetic data creation\nobs &lt;- nrow(data_filtered) #Number of observations\n\nsyn &lt;- data.frame(\n  \n  #Set non-mortality data to match the previous dataset\n  data_as_of = rep(as.Date('02/07/25', format = \"%m/%d/%y\"), obs),\n  jurisdiction_of_occurance = rep('United States', obs),\n  mmwr_year = c(rep(2020, nrow(filter(data_filtered, mmwr_year == 2020))),\n                rep(2021, nrow(filter(data_filtered, mmwr_year == 2021))),\n                rep(2022, nrow(filter(data_filtered, mmwr_year == 2022))),\n                rep(2023, nrow(filter(data_filtered, mmwr_year == 2023)))),\n  mmwr_week = c(1:nrow(filter(data_filtered, mmwr_year == 2020)),\n                1:nrow(filter(data_filtered, mmwr_year == 2021)),\n                1:nrow(filter(data_filtered, mmwr_year == 2022)),\n                1:nrow(filter(data_filtered, mmwr_year == 2023))),\n  \n  #Simulate the mortality variables using normal distributions\n  all_cause = rnorm(obs, mean = mean(data_filtered$all_cause), sd = sd(data_filtered$all_cause)),\n  natural_cause = rnorm(obs, mean = mean(data_filtered$natural_cause), sd = sd(data_filtered$natural_cause)),\n  cancer_count = rnorm(obs, mean = mean(data_filtered$cancer_count), sd = sd(data_filtered$cancer_count)),\n  diabetes_count = rnorm(obs, mean = mean(data_filtered$diabetes_count), sd = sd(data_filtered$diabetes_count)),\n  influenza_pneumonia_count = rnorm(obs, mean = mean(data_filtered$influenza_pneumonia_count), sd = sd(data_filtered$influenza_pneumonia_count)),\n  heart_disease_count = rnorm(obs, mean = mean(data_filtered$heart_disease_count), sd = sd(data_filtered$heart_disease_count))\n)\n\nAfter synthesizing the new dataset, I will plot histograms of each of the mortality variables and compare to the original dataset.\n\n#Plotting distributions\n#All-cause mortality\nggplot(syn, aes(x = all_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"All Cause Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of All Cause Mortality\"\n  )\n\n\n\n\n\n\n\n#Natural cause mortality\nggplot(syn, aes(x = natural_cause)) +\n  geom_histogram(binwidth = 500, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Natural Cause Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Natural Cause Mortality\"\n  )\n\n\n\n\n\n\n\n#Cancer mortality\nggplot(syn, aes(x = cancer_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Cancer Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Cancer Mortality\"\n  )\n\n\n\n\n\n\n\n#Diabetes mortality\nggplot(syn, aes(x = diabetes_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Diabetes Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Diabetes Mortality\"\n  )\n\n\n\n\n\n\n\n#Influenza and pneumonia mortality\nggplot(syn, aes(x = influenza_pneumonia_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Influenza and Pneumonia Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Influenza and Pneumonia Mortality\"\n  )\n\n\n\n\n\n\n\n#Heart disease mortality\nggplot(syn, aes(x = heart_disease_count)) +\n  geom_histogram(binwidth = 50, fill = \"skyblue\", color = \"black\") +\n  labs(\n    x = \"Heart Disease Mortality Count (Synthetic Data)\",\n    y = \"Frequency\",\n    title = \"Distribution of Heart Disease Mortality\"\n  )\n\n\n\n\n\n\n\n\nThese distributions match the original data well in terms of their range of values and where the mean lies. However, there are some variations in the shape of the data. While the mortality data in the original dataset was largely normal, some outliers that were present in the original data were gave some of the distributions a slight skew. The simulations here incorporated those outlier values in the main distrubution, so the shape of the distributions differed in the synthetic data."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html",
    "href": "fitting-exercise/fitting-exercise.html",
    "title": "Data Fitting Exercise",
    "section": "",
    "text": "First, start with loading the data using a relative path.\n\n# Load packages\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\n\n# Load the data\ndata_location &lt;- here::here(\"fitting-exercise\", \"data\", \"Mavoglurant_A2121_nmpk.csv\")\ndata &lt;- read.csv(data_location)"
  },
  {
    "objectID": "ml-models-exercise/ml-models-exercise.html",
    "href": "ml-models-exercise/ml-models-exercise.html",
    "title": "Machine Learning Models Exercise",
    "section": "",
    "text": "This exercise starts with loading packages, the data, and setting a seed.\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.3.3\n\n\nhere() starts at C:/Users/vince/OneDrive/Desktop/port-MADA/vincentnguyen-MADA-portfolio\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.3.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'broom' was built under R version 4.3.3\n\n\nWarning: package 'dials' was built under R version 4.3.3\n\n\nWarning: package 'scales' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'infer' was built under R version 4.3.3\n\n\nWarning: package 'modeldata' was built under R version 4.3.3\n\n\nWarning: package 'parsnip' was built under R version 4.3.3\n\n\nWarning: package 'recipes' was built under R version 4.3.3\n\n\nWarning: package 'rsample' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'tune' was built under R version 4.3.3\n\n\nWarning: package 'workflows' was built under R version 4.3.3\n\n\nWarning: package 'workflowsets' was built under R version 4.3.3\n\n\nWarning: package 'yardstick' was built under R version 4.3.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(dplyr)\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.3.3\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.3.3\n\nset.seed(1234)\nrngseed = 1234\ndata &lt;- readRDS(here(\"ml-models-exercise\", \"finaldata.rds\"))\n\nAs part of the assignment specifications, race needs to be standardized into 3 factor levels.\n\n# Change values 7 and 88 to be 3 instead\ndata &lt;- data %&gt;%\n  mutate(RACE = factor(case_when(\n    RACE %in% c(7, 88) ~ \"3\",\n    TRUE ~ as.character(RACE)\n  )))\n\nNext, we look at some pairwise correlations. Usually, strong correlations are removed from modeling but for this assignment, things look good as is.\n\n# Code from fitting-exercise; this is a correlation heatmap\n\nlibrary(reshape2)\n\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\nlibrary(RColorBrewer)\n\n# Calculation of correlations\ncor_matrix = cor(data[,c(\"Y\", \"DOSE\", \"WT\", \"HT\", \"AGE\")], method = \"pearson\")\nprint(cor_matrix)\n\n               Y       DOSE         WT          HT         AGE\nY     1.00000000 0.71808396 -0.2128719 -0.15832972  0.01256372\nDOSE  0.71808396 1.00000000  0.1012319  0.01877994  0.07201600\nWT   -0.21287194 0.10123185  1.0000000  0.59975050  0.11967399\nHT   -0.15832972 0.01877994  0.5997505  1.00000000 -0.35185806\nAGE   0.01256372 0.07201600  0.1196740 -0.35185806  1.00000000\n\n# Melt the correlation matrix for ggplot\ncor_matrix_melted &lt;- melt(cor_matrix)\n\n# Plot the heatmap\nggplot(cor_matrix_melted, aes(Var1, Var2, fill = value)) + \n  geom_tile() +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0, limit = c(-1, 1)) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Correlation Heatmap\", x = \"Variables\", y = \"Variables\")\n\n\n\n\n\n\n\n\nThis section entails the creation of 3 models using the TidyModels workflow. Model 1 is a linear regression model, model 2 is made with LASSO, and the last model utilizes random forest.\n\n# Calculate and create BMI column\ndata$BMI &lt;- data$WT / data$HT^2\n\nrecipe &lt;- recipe(Y ~ DOSE + AGE + SEX + RACE + WT + HT + BMI, data = data) %&gt;%\n  step_dummy(all_nominal_predictors())\n\n# set method for modeling\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\n# Insert recipe\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(recipe)\n\nlm_fit &lt;- lm_wf %&gt;%\n  add_model(lm_spec) %&gt;%\n  fit(data = data)\n\nlm_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\n# A tibble: 9 × 5\n  term         estimate std.error statistic  p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  32051.    10161.       3.15  2.07e- 3\n2 DOSE            59.1       4.73    12.5   6.22e-23\n3 AGE              4.53      7.47     0.607 5.45e- 1\n4 WT             145.       59.5      2.45  1.60e- 2\n5 HT          -16840.     5728.      -2.94  4.00e- 3\n6 BMI           -536.      188.      -2.85  5.20e- 3\n7 SEX_X2        -435.      210.      -2.07  4.06e- 2\n8 RACE_X2        158.      124.       1.27  2.07e- 1\n9 RACE_X3       -258.      215.      -1.20  2.33e- 1\n\n# Set method for LASSO\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n# Insert recipe\nlasso_wf &lt;- workflow() %&gt;%\n  add_recipe(recipe)\n\nlasso_fit &lt;- lasso_wf %&gt;%\n  add_model(lasso_spec) %&gt;%\n  fit(data = data)\n\nlasso_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\n# A tibble: 9 × 3\n  term         estimate penalty\n  &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  30579.       0.1\n2 DOSE            59.2      0.1\n3 AGE              4.43     0.1\n4 WT             137.       0.1\n5 HT          -16009.       0.1\n6 BMI           -508.       0.1\n7 SEX_X2        -431.       0.1\n8 RACE_X2        158.       0.1\n9 RACE_X3       -251.       0.1\n\n# Set method for random forest\nforest_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\", seed = rngseed)\n\n# Insert recipe\nforest_wf &lt;- workflow() %&gt;%\n  add_recipe(recipe)\n\n# Create model with all predictors and random forest\nforest_fit &lt;- forest_wf %&gt;%\n add_model(forest_spec) %&gt;%\n  fit(data = data)\n\n\n# Make predictions and calculate RMSE with models\n\n# Linear Model\nlm_preds &lt;- predict(lm_fit, new_data = data)\nlm_preds &lt;- tibble(truth = data$Y, predicted = lm_preds$.pred)\nlm_rmse &lt;- lm_preds %&gt;%\n  metrics(truth = truth, estimate = predicted)\nprint(lm_rmse)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     572.   \n2 rsq     standard       0.644\n3 mae     standard     443.   \n\n# Lasso Model\nlasso_preds &lt;- predict(lasso_fit, new_data = data)\nlasso_preds &lt;- tibble(truth = data$Y, predicted = lasso_preds$.pred)\nlasso_rmse &lt;- lasso_preds %&gt;%\n  metrics(truth = truth, estimate = predicted)\nprint(lasso_rmse)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     572.   \n2 rsq     standard       0.644\n3 mae     standard     442.   \n\n# Forest\nforest_preds &lt;- predict(forest_fit, new_data = data)\nforest_preds &lt;- tibble(truth = data$Y, predicted = forest_preds$.pred)\nforest_rmse &lt;- forest_preds %&gt;%\n  metrics(truth = truth, estimate = predicted)\nprint(forest_rmse)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     382.   \n2 rsq     standard       0.893\n3 mae     standard     297.   \n\n\n\n\n\n# Seed Seed\nset.seed(1234)\n\n# tune lasso\ntune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n# create grid\nlasso_grid &lt;- tibble(penalty = 10^seq(-5, 2, length.out = 50))\n\n# Resample using apparent\nlasso_resample &lt;- apparent(data)\n\n# Tune grid\nset.seed(1234)\nlasso_tune_res &lt;- tune_grid(\n  lasso_wf %&gt;% add_model(tune_spec),\n  resamples = lasso_resample,\n  grid = lasso_grid,\n  metrics = metric_set(rmse, rsq)\n)\n\n# collect metrics\nlasso_tune_res %&gt;%\n  collect_metrics()\n\n# A tibble: 50 × 7\n     penalty .metric .estimator  mean     n std_err .config              \n       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 0.00001   &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model01\n 2 0.0000139 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model02\n 3 0.0000193 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model03\n 4 0.0000268 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model04\n 5 0.0000373 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model05\n 6 0.0000518 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model06\n 7 0.0000720 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model07\n 8 0.0001    &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model08\n 9 0.000139  &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model09\n10 0.000193  &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model10\n# ℹ 40 more rows\n\n# getting error that autoplot(lasso_tune_res) does not work because of apparent()\n\n\n# Tuning forest\nforest_spec &lt;- rand_forest(\n  mode = \"regression\", \n  trees = 300, \n  mtry = tune(), \n  min_n = tune()\n) %&gt;%\n  set_engine(\"ranger\")\n\n# Create grid with set parameters\nforest_grid &lt;- grid_regular(\n  mtry(range = c(1, 7)),  \n  min_n(range = c(1, 21)),  \n  levels = 7  \n)\n\n# Resample using apparent\nforest_resample &lt;- apparent(data)\n\n# Tune forest\nset.seed(1234)\nforest_tune_res &lt;- tune_grid(\n  forest_wf %&gt;% add_model(forest_spec),\n  resamples = forest_resample, \n  grid = forest_grid, \n  metrics = metric_set(rmse, rsq)\n)\n\n# getting error that autoplot(forest_tune_res) does not work because of apparent()\n\n\n\n\n\n# Set seed\nset.seed(1234)\n\n# 5 fold crossvalidation repeated 5 times\ncv_folds &lt;- vfold_cv(data, v = 5, repeats = 5)\n\n# Tune the grid\nlasso_tune_res &lt;- tune_grid(\n  lasso_wf %&gt;% add_model(tune_spec),\n  resamples = cv_folds,\n  grid = lasso_grid,\n  metrics = metric_set(rmse, rsq)\n)\n\n# Plot results\nautoplot(lasso_tune_res)\n\n\n\n\n\n\n\n# Tune the forest\nforest_tune_res &lt;- tune_grid(\n  forest_wf %&gt;% add_model(forest_spec),\n  resamples = cv_folds,  \n  grid = forest_grid,\n  metrics = metric_set(rmse, rsq)\n)\n\n# Plot results\nautoplot(forest_tune_res)"
  },
  {
    "objectID": "ml-models-exercise/ml-models-exercise.html#the-next-two-coding-chunks-entail-basic-tuning-of-models-without-the-use-of-cross-validation.",
    "href": "ml-models-exercise/ml-models-exercise.html#the-next-two-coding-chunks-entail-basic-tuning-of-models-without-the-use-of-cross-validation.",
    "title": "Machine Learning Models Exercise",
    "section": "",
    "text": "# Seed Seed\nset.seed(1234)\n\n# tune lasso\ntune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n# create grid\nlasso_grid &lt;- tibble(penalty = 10^seq(-5, 2, length.out = 50))\n\n# Resample using apparent\nlasso_resample &lt;- apparent(data)\n\n# Tune grid\nset.seed(1234)\nlasso_tune_res &lt;- tune_grid(\n  lasso_wf %&gt;% add_model(tune_spec),\n  resamples = lasso_resample,\n  grid = lasso_grid,\n  metrics = metric_set(rmse, rsq)\n)\n\n# collect metrics\nlasso_tune_res %&gt;%\n  collect_metrics()\n\n# A tibble: 50 × 7\n     penalty .metric .estimator  mean     n std_err .config              \n       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 0.00001   &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model01\n 2 0.0000139 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model02\n 3 0.0000193 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model03\n 4 0.0000268 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model04\n 5 0.0000373 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model05\n 6 0.0000518 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model06\n 7 0.0000720 &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model07\n 8 0.0001    &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model08\n 9 0.000139  &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model09\n10 0.000193  &lt;NA&gt;    &lt;NA&gt;          NA    NA      NA Preprocessor1_Model10\n# ℹ 40 more rows\n\n# getting error that autoplot(lasso_tune_res) does not work because of apparent()\n\n\n# Tuning forest\nforest_spec &lt;- rand_forest(\n  mode = \"regression\", \n  trees = 300, \n  mtry = tune(), \n  min_n = tune()\n) %&gt;%\n  set_engine(\"ranger\")\n\n# Create grid with set parameters\nforest_grid &lt;- grid_regular(\n  mtry(range = c(1, 7)),  \n  min_n(range = c(1, 21)),  \n  levels = 7  \n)\n\n# Resample using apparent\nforest_resample &lt;- apparent(data)\n\n# Tune forest\nset.seed(1234)\nforest_tune_res &lt;- tune_grid(\n  forest_wf %&gt;% add_model(forest_spec),\n  resamples = forest_resample, \n  grid = forest_grid, \n  metrics = metric_set(rmse, rsq)\n)\n\n# getting error that autoplot(forest_tune_res) does not work because of apparent()"
  },
  {
    "objectID": "ml-models-exercise/ml-models-exercise.html#the-next-two-coding-chunks-entail-basic-tuning-of-models-withthe-use-of-cross-validation.",
    "href": "ml-models-exercise/ml-models-exercise.html#the-next-two-coding-chunks-entail-basic-tuning-of-models-withthe-use-of-cross-validation.",
    "title": "Machine Learning Models Exercise",
    "section": "",
    "text": "# Set seed\nset.seed(1234)\n\n# 5 fold crossvalidation repeated 5 times\ncv_folds &lt;- vfold_cv(data, v = 5, repeats = 5)\n\n# Tune the grid\nlasso_tune_res &lt;- tune_grid(\n  lasso_wf %&gt;% add_model(tune_spec),\n  resamples = cv_folds,\n  grid = lasso_grid,\n  metrics = metric_set(rmse, rsq)\n)\n\n# Plot results\nautoplot(lasso_tune_res)\n\n\n\n\n\n\n\n# Tune the forest\nforest_tune_res &lt;- tune_grid(\n  forest_wf %&gt;% add_model(forest_spec),\n  resamples = cv_folds,  \n  grid = forest_grid,\n  metrics = metric_set(rmse, rsq)\n)\n\n# Plot results\nautoplot(forest_tune_res)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#part-2",
    "href": "fitting-exercise/fitting-exercise.html#part-2",
    "title": "Data Fitting Exercise",
    "section": "Part 2",
    "text": "Part 2\n\nThis section was contributed by Connor Norris\n\n#Put predicted and observed values of each model in a new data frame\n#Data frame for model fitting Y from dose\nmodel1_res &lt;- data.frame(\n  truth = train_data$Y,\n  pred = dose_predictions_lm$.pred,\n  model = rep(1, nrow(train_data))\n)\n\n#Data frame for model fitting Y from all predictors\nmodel2_res &lt;- data.frame(\n  truth = train_data$Y,\n  pred = all_predictions_lm$.pred,\n  model = rep(2, nrow(train_data))\n)\n\n#Data frame for null model\nnull_mod_res &lt;- data.frame(\n  truth = train_data$Y,\n  pred = null_predictions$.pred,\n  model = rep(\"null\", nrow(train_data))\n)\n\n#Add all model results together\nmodel_res &lt;- rbind(model1_res, model2_res, null_mod_res)\n\n#Plot predicted vs. observed values for all models\nggplot(data = model_res, aes(x = truth, y = pred, colour = model)) +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1) +\n  labs(\n    x = \"Observed Value\",\n    y = \"Predicted Value\",\n    title = \"Observed vs. Predicted Values of Y from 3 Models\",\n    colour = \"Model\"\n  ) +\n  scale_x_continuous(limits = c(0, 5000)) +\n  scale_y_continuous(limits = c(0, 5000))\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n#Calculate residuals for model 2\nmodel2_res &lt;- mutate(model2_res, residuals = pred - truth)\n\n#Plot the residuals of model 2\nggplot(model2_res, aes(x = pred, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0) + \n  labs(\n    x = \"Predicted Values\",\n    y = \"Residuals\",\n    title = \"Predicted Values vs. Residuals\"\n  )\n\n\n\n\n\n\n\n\n\n#Reset seed\nset.seed(rngseed)\n\n#Generate bootstrap samples\nbootstraps &lt;- bootstraps(data = train_data, times = 1000)\n\n#Fit the model and make predictions for each bootstrap sample\npredictions_list &lt;- map(bootstraps$splits, function(split) {\n  #Extract the bootstrap sample\n  boot_data &lt;- analysis(split)\n  \n  #Fit the model (replace this with your model)\n  model &lt;- lm_mod %&gt;%\n    fit(Y ~ ., data = boot_data)\n  \n  # Make predictions on the original training data\n  preds &lt;- predict(model, new_data = train_data)\n  \n  return(preds)\n})\n\n#Convert the list to a data frame for easier handling\npredictions_df &lt;- as.data.frame(do.call(cbind, predictions_list))\n\n#View first few rows\nhead(predictions_df)\n\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3118.049 3377.414 3396.213 3559.537 3202.972 3551.132 3241.293 3226.950\n2 1894.039 1797.195 1823.856 1789.627 2034.767 2013.899 1942.319 2435.522\n3 2628.676 2688.714 2811.656 2983.137 2633.832 3002.580 2654.623 2785.723\n4 2165.134 1672.769 2466.482 2060.677 1705.904 2249.481 1913.210 2173.041\n5 2710.403 2999.897 2926.685 3128.095 2933.146 3049.338 2941.660 2892.655\n6 1370.259 1125.656 1422.034 1376.286 1252.113 1444.337 1176.821 1149.336\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3136.336 3179.096 3029.501 3300.707 3102.583 3513.390 3181.119 3282.982\n2 1975.773 2079.594 1945.819 1918.128 1892.097 1953.346 2133.031 1861.590\n3 2588.082 2737.537 2614.509 2801.703 2611.766 2877.787 2701.836 2737.435\n4 1872.509 2429.033 2653.229 2181.152 2291.690 2043.071 1794.137 2356.652\n5 2860.756 2685.052 2482.011 2766.811 2651.686 3160.198 2799.997 2749.582\n6 1457.908 1100.011 1163.116 1404.853 1174.640 1304.596 1158.159 1100.501\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3458.832 3383.879 3317.100 3374.846 3541.555 3382.548 3489.631 3153.845\n2 1859.052 1773.833 1995.189 1870.326 1838.687 1892.993 1983.438 2074.121\n3 2826.186 2706.398 2728.435 2830.428 2859.499 2741.329 2913.898 2649.305\n4 2146.585 1858.408 1948.644 2154.989 1791.033 1942.435 2392.760 2090.856\n5 3117.033 2991.890 2862.946 2886.482 3145.978 3053.254 2953.071 2866.756\n6 1489.680 1183.190 1061.929 1224.337 1460.472 1467.321 1298.316 1470.001\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3374.290 3345.776 3604.511 3288.825 3400.516 3415.521 3382.655 3147.702\n2 1817.077 1870.120 2067.144 1905.958 1994.309 1922.074 1943.433 2258.341\n3 2779.060 2692.050 2964.910 2750.002 2807.661 2798.764 2789.694 2619.084\n4 2189.395 1805.950 2000.973 2175.122 1790.575 1852.822 2069.525 1744.487\n5 2951.001 2928.895 3231.999 2871.940 3126.709 3039.804 2888.360 2924.765\n6 1260.486 1066.846 1099.021 1478.388 1586.588 1310.261 1350.567 1540.505\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3428.460 3347.627 3570.165 3459.649 3352.730 3533.358 3431.203 3305.622\n2 1789.664 2054.541 1931.658 1869.953 1889.359 2051.926 2075.011 1851.254\n3 2745.532 2793.685 2848.987 2819.442 2819.501 2833.698 2936.223 2722.434\n4 1979.546 1859.764 1741.358 2298.333 2376.932 1977.932 2201.657 1782.626\n5 3029.974 2953.322 3132.040 2971.265 2814.393 3269.108 3036.377 2885.537\n6 1172.014 1470.901 1310.151 1207.908 1212.929 1368.191 1259.359 1184.847\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3326.814 3285.773 3221.032 3475.499 3301.655 3182.335 3082.073 3296.583\n2 1742.690 2012.275 1639.005 2007.201 1807.328 2092.494 1732.123 2097.016\n3 2667.673 2714.155 2565.260 2864.330 2780.069 2698.283 2512.184 2825.039\n4 2183.087 1949.190 1840.365 2248.378 2139.959 1871.494 2003.838 2051.623\n5 2909.368 2936.269 2862.625 3071.967 2814.935 2748.814 2668.243 2872.891\n6 1195.818 1308.271 1557.579 1322.467 1402.364 1380.943 1326.914 1451.240\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3282.698 3300.100 3352.876 3286.290 3084.205 3328.305 3453.378 3431.691\n2 2129.427 2007.016 2081.255 1999.220 1736.445 2025.733 2126.732 1619.281\n3 2772.054 2728.975 2836.326 2676.625 2504.041 2772.815 2818.753 2769.372\n4 2124.195 1994.192 2060.896 1921.808 2025.761 2387.728 2086.413 2026.558\n5 2923.982 2959.597 2968.357 2956.507 2691.714 2946.517 3108.662 2984.359\n6 1255.860 1337.682 1424.496 1247.014 1213.976 1397.096 1241.247 1347.208\n     .pred     .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3363.097 3601.5052 3119.511 3343.330 3215.743 3504.107 3485.721 3377.325\n2 1942.108 1814.2854 2011.017 2103.928 1752.643 2050.934 2204.225 1695.524\n3 2735.505 2833.4040 2668.892 2760.945 2653.673 2930.765 2884.311 2771.881\n4 1942.146 2273.4739 2039.654 1783.153 2024.552 2019.559 1981.041 2214.556\n5 2991.288 3053.0886 2640.106 3028.110 2741.514 3110.247 3105.492 2933.036\n6 1005.741  721.3273 1343.990 1293.624 1283.632 1424.032 1094.534 1553.180\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3238.066 3500.726 3249.458 3139.613 3320.916 3277.785 3177.906 3742.280\n2 1944.900 1889.829 2024.794 2097.373 1979.504 1793.411 2373.487 1653.250\n3 2798.648 2874.840 2777.833 2591.902 2760.449 2705.089 2800.215 2999.013\n4 2307.969 2308.477 2153.106 1614.057 2142.149 2046.208 2380.620 2085.299\n5 2724.674 3070.423 2803.176 2915.348 2957.835 2726.082 2772.682 3253.004\n6 1207.825 1412.247 1224.933 1412.984 1298.741 1327.204 1250.500 1436.895\n      .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3262.1724 3383.248 3356.856 3112.735 3466.789 3205.077 3175.987 3204.015\n2 2143.2409 1835.775 2134.306 1970.137 1996.710 1997.073 2006.053 2190.822\n3 2774.2513 2745.504 2770.717 2634.863 2903.523 2702.859 2708.797 2746.160\n4 2131.0584 1835.114 2216.006 2093.940 2225.443 1814.954 2140.832 2231.448\n5 2817.8690 3040.318 2994.104 2716.122 2993.096 2847.830 2753.153 2760.479\n6  972.1687 1254.286 1071.661 1161.159 1343.557 1294.402 1220.288 1081.317\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3497.329 3396.743 3119.912 3447.781 3280.284 3251.766 3088.552 3208.082\n2 1768.445 1707.086 1801.329 2134.494 1850.367 1664.280 1689.717 1701.454\n3 2790.494 2762.800 2607.506 2932.071 2661.933 2695.155 2547.967 2607.252\n4 1856.457 2239.514 2092.138 1799.980 2441.805 2233.497 2223.275 2201.169\n5 3141.901 2853.651 2694.596 2995.780 2914.307 2709.891 2656.236 2763.412\n6 1353.361 1340.107 1512.180 1207.106 1137.763 1326.445 1440.846 1315.008\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3278.849 3364.121 3085.221 3435.922 3424.580 3062.451 3132.740 3393.837\n2 2167.951 1988.385 1816.683 1780.025 1913.067 2066.175 2043.186 2014.641\n3 2720.582 2766.467 2587.717 2812.935 2853.606 2626.777 2725.305 2792.006\n4 1811.264 2228.697 2097.504 2101.523 2006.873 2212.782 2245.376 2199.142\n5 2949.373 2880.470 2663.144 2958.244 3007.624 2677.088 2615.595 2987.422\n6 1195.869 1281.321 1395.082 1060.964 1424.364 1364.999 1209.742 1053.177\n     .pred    .pred     .pred    .pred    .pred    .pred    .pred    .pred\n1 3453.918 3429.439 3528.9594 3448.177 3252.513 3190.475 3184.264 3147.606\n2 1629.045 2162.647 1899.8051 2083.217 1951.182 2052.096 1993.086 2208.969\n3 2746.835 2900.326 2903.1398 2871.171 2659.536 2671.031 2612.069 2728.579\n4 2047.466 2073.921 2187.5092 1933.898 2091.655 2337.932 1926.503 1872.603\n5 3042.071 3108.555 2981.0861 3000.199 2869.256 2965.660 2846.328 2750.292\n6 1452.892 1381.084  997.0608 1123.498 1387.671 1537.237 1416.430 1234.142\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3289.738 3356.528 3325.594 3331.494 3351.061 3238.238 3454.862 3154.506\n2 1938.836 1959.620 1931.511 2043.779 1834.160 1852.531 1854.950 1867.638\n3 2786.355 2860.568 2756.854 2731.090 2695.872 2701.156 2942.366 2565.117\n4 2062.508 2197.451 2083.149 2117.824 1565.191 2046.468 2535.984 2110.549\n5 2952.636 2982.402 2870.129 2990.611 3035.182 2715.905 2860.616 2802.249\n6 1357.326 1493.830 1374.013 1208.127 1453.037 1139.976 1277.545 1226.574\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3301.473 3206.774 3491.313 3395.425 3547.687 3349.172 3172.355 3481.844\n2 1988.526 1967.589 1811.047 2037.208 2020.532 1932.095 1743.278 1866.883\n3 2739.136 2664.995 2858.650 2810.329 2958.964 2803.209 2647.218 2896.333\n4 1926.274 1954.341 2105.779 1929.080 2246.586 1999.422 2175.639 2199.965\n5 2861.214 2814.878 2996.410 2962.593 3099.130 2857.305 2718.683 3017.219\n6 1085.043 1409.101 1179.659 1344.676 1056.194 1255.845 1332.850 1545.549\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3299.541 3157.880 3492.361 3436.747 3077.371 3257.808 3269.125 3234.011\n2 1867.358 2098.535 1974.572 2129.034 2056.046 1899.201 1845.428 1794.871\n3 2711.849 2668.680 2945.018 2782.147 2706.402 2711.169 2647.813 2715.651\n4 2151.963 2333.061 2030.145 1819.860 2279.983 2085.593 2119.432 2279.479\n5 2831.008 2809.456 3089.185 3245.797 2630.686 2850.337 2842.618 2735.493\n6 1273.325 1161.980 1585.574 1449.849 1405.489 1301.227 1358.026 1387.280\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3227.418 3265.269 3129.897 3244.188 3169.061 3355.036 3244.714 3252.418\n2 1876.596 1793.345 1981.264 2063.037 1794.802 1771.989 2056.820 2012.694\n3 2657.769 2655.513 2539.028 2728.435 2724.939 2788.998 2756.210 2689.779\n4 1932.350 2206.937 1908.640 2077.011 2490.074 2204.402 2143.161 2208.590\n5 2860.847 2800.900 2842.601 2896.394 2547.030 2849.232 2891.286 2784.379\n6 1121.147 1210.978 1438.823 1183.819 1140.592 1333.555 1337.882 1127.986\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3398.082 3315.777 3234.231 3412.268 3034.961 3288.134 3305.104 3062.565\n2 2173.831 2082.627 2165.951 1837.920 2121.197 1809.269 2034.724 2205.903\n3 2822.161 2873.107 2640.463 2835.826 2669.630 2744.734 2790.395 2675.263\n4 2022.612 2366.078 1843.524 2302.322 2160.274 2203.241 2033.949 2139.571\n5 3094.982 2790.384 2965.385 2880.583 2610.737 2830.027 2900.766 2653.658\n6 1234.113 1177.960 1231.986 1135.809 1261.237 1289.835 1348.949 1275.100\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3245.805 3220.656 3417.150 3184.214 3253.867 3343.240 3160.676 3269.015\n2 1893.636 1842.178 2189.676 2126.582 1838.533 1669.657 2147.135 1890.440\n3 2706.936 2641.567 2977.582 2713.476 2667.188 2656.407 2706.189 2717.320\n4 1927.092 1876.140 2200.693 2048.466 2116.056 2183.069 2106.535 2169.129\n5 2850.826 2816.787 2900.086 2965.448 2857.526 2909.783 2695.065 2821.934\n6 1412.937 1203.529 1237.522 1520.953 1360.790 1078.671 1255.323 1193.966\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3602.252 3315.421 3058.142 3220.078 3307.462 3414.161 3266.552 3332.531\n2 1949.246 2332.337 1932.934 1728.538 1972.155 1505.774 2033.875 2144.478\n3 2936.350 2932.350 2584.384 2626.032 2771.613 2727.997 2653.497 2736.241\n4 1983.684 2079.497 1978.854 2033.863 2146.168 2422.691 1678.908 1890.478\n5 3137.252 2798.192 2680.430 2854.266 2867.102 2930.969 2974.561 2983.011\n6 1138.120 1094.341 1317.602 1395.414 1207.013 1350.904 1293.879 1113.177\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3196.177 3343.012 3461.676 3343.006 3644.657 3221.032 3388.638 3272.195\n2 1612.761 1851.231 1931.977 1919.172 1880.384 1758.738 1898.738 1787.127\n3 2598.287 2695.325 2833.661 2769.991 2945.204 2636.689 2788.200 2769.554\n4 2124.544 2196.606 1922.140 2048.425 2037.248 2108.342 2156.681 2443.882\n5 2804.155 2963.325 3115.131 2961.227 3145.235 2722.438 2914.847 2737.215\n6 1360.682 1098.501 1234.062 1517.545 1294.737 1076.158 1161.177 1298.635\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3363.045 3430.269 3355.448 3292.838 3514.337 3310.542 3393.114 3448.082\n2 1721.389 2060.176 2449.620 1996.466 1816.756 2023.676 1598.576 1675.565\n3 2729.350 2819.441 2905.715 2718.439 2829.542 2791.225 2676.068 2797.547\n4 2204.464 2283.942 2219.029 1922.610 2001.142 2140.090 2270.872 2167.074\n5 2947.331 2997.296 3049.543 2986.678 3188.032 2927.717 2844.493 2890.347\n6 1309.561 1166.376 1492.369 1309.318 1495.546 1468.030 1089.562 1004.534\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3423.381 3455.492 3283.640 3348.859 3328.881 3324.555 3459.576 3166.697\n2 2192.293 2117.043 2170.945 2164.920 1866.225 1729.113 1920.083 2010.923\n3 2863.129 2934.721 2865.131 2837.674 2639.526 2690.077 2874.603 2655.760\n4 1885.505 2036.572 2284.936 1835.077 2100.594 2024.576 1941.376 1976.228\n5 3141.390 3100.011 2817.138 3072.261 2970.648 2967.383 2941.334 2816.984\n6 1520.219 1361.538 1245.125 1485.278 1162.108 1593.419 1278.685 1251.281\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3300.450 3284.763 3392.817 3394.055 3342.199 3403.427 3513.228 3250.471\n2 2101.125 1653.977 2060.500 2138.062 1947.785 1801.367 1901.195 1895.045\n3 2799.202 2629.788 2784.860 2856.280 2729.422 2667.208 2935.510 2664.886\n4 2086.133 2066.580 1982.066 1947.871 1907.196 1822.694 2917.707 1953.108\n5 2959.817 2922.875 3044.012 2956.420 3016.494 3084.419 2955.329 2932.020\n6 1341.141 1457.845 1185.143 1417.810 1514.243 1272.811 1335.291 1582.706\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3110.020 3264.670 3467.531 3280.516 3360.232 3044.591 3177.138 3365.132\n2 2325.632 2139.353 1910.707 2182.329 1904.095 2062.080 1886.992 1840.217\n3 2715.111 2752.190 2855.303 2785.169 2791.351 2615.149 2665.491 2807.246\n4 2072.179 2069.304 1972.146 2376.350 1861.227 2182.429 2017.043 2019.319\n5 2850.615 2876.478 3020.798 2843.651 2986.715 2739.691 2817.020 2876.026\n6 1297.439 1260.413 1323.651 1248.081 1266.276 1442.831 1611.937 1448.515\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3408.332 3588.192 3281.820 3393.095 3357.604 3479.207 3411.889 3371.341\n2 1969.288 1772.314 2102.101 1844.468 1898.410 2012.751 2180.131 1949.339\n3 2849.497 2883.706 2806.058 2744.374 2800.546 2905.017 2825.630 2839.568\n4 2329.898 2073.379 1957.778 2138.022 2250.827 1810.690 2176.993 2104.433\n5 2861.975 3100.747 2950.588 2948.883 2947.229 3003.117 3036.741 2884.642\n6 1052.212 1213.967 1523.077 1136.326 1423.699 1217.139 1253.498 1239.267\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3292.699 3477.110 3415.226 3196.655 3503.877 3361.067 3351.818 3348.618\n2 1905.954 1911.532 1815.213 2018.206 1964.366 2086.666 1877.329 1881.837\n3 2668.097 2815.112 2806.047 2764.847 2794.704 2815.733 2728.450 2741.553\n4 2135.652 1769.169 2179.708 2429.922 2312.346 2095.563 1868.616 2160.394\n5 2937.939 3073.115 2993.700 2685.454 3119.493 3019.067 2988.524 2942.455\n6 1227.818 1237.517 1465.021 1359.496 1286.193 1287.396 1155.117 1401.183\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3095.995 3226.465 3462.770 3384.781 3225.095 3141.834 3426.118 3237.685\n2 1786.372 1975.196 2144.967 1907.755 2130.842 2043.977 1862.622 2103.254\n3 2523.692 2651.494 2977.735 2761.624 2777.316 2626.064 2799.743 2776.255\n4 1904.602 1945.302 2041.190 1974.414 2151.080 2146.523 2040.462 2058.269\n5 2768.160 2829.141 2880.280 2991.520 2808.181 2779.364 3020.424 2833.348\n6 1187.199 1030.116 1009.574 1161.164 1034.805 1042.393 1282.791 1352.270\n     .pred    .pred    .pred    .pred    .pred    .pred     .pred    .pred\n1 3214.893 3209.344 3431.186 3544.505 3036.819 3334.558 3339.9948 3235.983\n2 1955.892 1721.101 2020.309 1709.945 2001.751 1723.008 2050.2367 2223.216\n3 2725.404 2608.218 2842.920 2950.148 2638.257 2807.212 2836.4027 2744.437\n4 2125.227 2004.121 1902.509 2275.803 2164.980 2459.215 1986.6335 1907.752\n5 2812.441 2814.939 2986.830 3035.679 2638.302 2698.945 2802.1271 3027.011\n6 1356.045 1446.555 1031.986 1329.792 1586.477 1133.927  793.2688 1796.388\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3222.871 3337.939 3371.566 3473.549 3250.144 3442.172 3293.051 3130.810\n2 1794.570 1770.622 1948.511 1917.298 2053.645 1868.504 1983.809 2099.236\n3 2660.829 2745.572 2777.931 2801.399 2656.237 2735.139 2709.431 2709.052\n4 2262.685 2138.759 2142.806 2190.014 1593.950 1986.661 2064.152 2222.575\n5 2702.792 2961.640 2954.804 3027.963 2879.761 3042.685 2939.508 2673.860\n6 1083.395 1528.569 1186.103 1010.350 1172.762 1148.872 1288.789 1260.385\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3237.672 3102.633 3214.047 3155.194 3467.372 3359.792 3285.296 3585.642\n2 1968.652 1830.030 2125.249 1961.200 1932.594 1911.887 2049.561 1723.316\n3 2719.505 2534.576 2671.322 2634.189 2895.219 2716.528 2701.214 2912.188\n4 2523.898 1949.152 1886.322 1830.682 2470.350 1772.693 1938.889 2486.851\n5 2858.595 2724.878 3012.884 2736.160 3025.459 3002.768 2999.023 3015.031\n6 1483.800 1225.948 1382.836 1224.786 1333.826 1117.792 1292.654 1261.578\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3309.339 3287.046 3138.641 3234.384 3404.956 3503.813 3403.215 3315.706\n2 1857.572 1973.510 1740.701 1911.788 2053.296 2056.669 2091.998 1878.657\n3 2699.333 2651.809 2613.058 2702.888 2775.130 2857.319 2880.806 2784.465\n4 1991.638 1939.049 2310.715 2010.266 1908.784 2113.141 1972.627 2304.269\n5 2883.436 3035.808 2636.121 2869.880 3148.686 3146.498 2942.256 2773.419\n6 1312.662 1345.871 1211.432 1567.737 1410.120 1213.791 1133.922 1348.073\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3077.737 3438.638 3425.340 3163.789 3290.934 3443.035 3057.401 3263.529\n2 1974.266 1866.348 1855.747 1917.288 1867.536 1883.226 2062.064 1900.868\n3 2617.719 2846.872 2816.412 2592.988 2709.273 2910.140 2605.960 2731.280\n4 2199.721 2078.023 2154.137 1737.461 1827.817 2306.106 2182.033 1904.038\n5 2699.832 3044.406 3050.126 2779.057 2897.307 2836.020 2768.468 2897.100\n6 1357.326 1456.465 1430.099 1197.462 1211.430 1197.153 1617.282 1385.254\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3595.064 3358.558 3508.791 3456.986 3499.153 3297.589 3389.872 3532.371\n2 2136.601 2010.769 1975.496 1784.766 2083.543 1835.438 1889.341 1803.995\n3 3058.238 2746.153 2877.606 2909.454 2883.851 2687.361 2693.945 2827.634\n4 2268.432 2015.690 2345.220 2287.374 2225.121 1873.439 1852.654 2159.007\n5 3125.242 3049.062 3115.643 2923.603 3100.156 2856.119 3112.500 3141.293\n6 1166.903 1174.343 1364.182 1472.519 1229.581 1209.504 1464.565 1418.957\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3221.164 3240.669 3438.637 3311.985 3628.322 3505.132 3270.283 3408.292\n2 1996.594 2014.722 1768.634 1754.112 2160.008 1974.295 1863.376 1955.367\n3 2610.079 2791.194 2757.972 2625.624 2982.484 2892.012 2687.153 2825.037\n4 2092.712 2452.566 1769.740 1800.238 1920.627 2230.950 2153.172 1986.856\n5 2927.825 2721.860 2958.274 2966.242 3271.060 3045.718 2811.746 3030.733\n6 1307.353 1175.869 1102.152 1526.506 1173.439 1176.071 1188.204 1250.383\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3200.509 3226.734 3363.209 3195.180 3239.448 3389.857 3242.686 3351.351\n2 2135.083 2106.891 2065.769 1885.364 1935.896 1999.668 1748.765 1726.452\n3 2718.196 2761.578 2808.803 2626.769 2733.327 2807.459 2604.246 2781.323\n4 2132.474 2168.765 1935.197 2039.651 2398.722 2118.768 1896.843 2476.684\n5 2829.778 2781.178 2941.579 2822.596 2773.140 3015.457 2842.029 2947.133\n6 1316.467 1350.043 1189.802 1180.822 1413.458 1323.163 1455.817 1670.628\n     .pred    .pred    .pred    .pred     .pred    .pred    .pred    .pred\n1 3189.178 3427.603 3350.690 3207.517 3385.4796 3414.254 3344.947 3284.297\n2 1835.375 1848.860 1945.370 2100.459 1926.9986 2220.273 2044.739 1875.162\n3 2684.425 2763.729 2808.331 2664.658 2749.6143 2875.773 2779.054 2668.585\n4 2256.414 2033.002 2255.139 2144.067 1966.8183 1932.876 2459.383 1941.740\n5 2729.974 3024.432 2895.362 2857.972 2901.0131 3055.886 3005.033 2990.273\n6 1334.002 1157.761 1234.197 1139.549  845.6062 1461.741 1213.660 1573.632\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3349.093 3268.446 3324.554 3470.151 3331.792 3495.830 3388.238 3340.072\n2 1884.284 1866.444 1898.926 1963.454 1974.666 1918.115 1857.651 2011.714\n3 2886.120 2720.918 2699.711 2896.895 2697.653 2849.378 2781.429 2732.794\n4 2771.948 2181.010 1982.296 2044.719 1855.049 1994.291 2169.301 1715.381\n5 2708.742 2835.772 2911.789 2966.421 3053.951 3095.664 3037.884 3063.279\n6 1132.712 1298.899 1163.695 1282.009 1018.196 1164.959 1421.900 1525.846\n     .pred    .pred    .pred    .pred     .pred    .pred    .pred    .pred\n1 3345.647 3317.895 3230.482 3345.742 3080.8477 3329.358 3169.253 3610.500\n2 2019.311 2170.429 2052.752 1884.774 2057.4492 1831.515 1831.613 2023.324\n3 2756.465 2788.908 2697.896 2810.516 2621.5465 2763.044 2630.258 2978.011\n4 1865.548 2053.251 2048.425 2327.499 1931.5456 2149.146 2285.365 2105.889\n5 2948.437 2949.679 2961.103 2894.937 2583.5819 2838.843 2671.166 3133.052\n6 1176.781 1164.708 1476.073 1450.300  873.0088 1395.007 1384.538 1171.714\n     .pred    .pred    .pred    .pred    .pred     .pred    .pred    .pred\n1 3267.448 3291.854 3338.130 2990.089 3371.056 3414.0989 3302.314 3345.803\n2 1939.993 2085.937 2007.701 1950.286 1978.388 2079.5993 1837.846 1719.243\n3 2667.232 2679.418 2712.250 2664.892 2745.584 2817.4560 2655.089 2630.109\n4 2058.463 1963.733 1954.548 2300.050 1775.823 1823.3312 2086.185 1783.112\n5 2836.470 3064.986 2926.986 2431.353 3013.337 2986.0383 2984.437 3102.956\n6 1196.529 1427.733  986.939 1258.903 1267.161  984.1427 1226.949 1541.321\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3370.299 3348.140 3355.572 3311.604 3504.748 3589.551 3336.433 3241.811\n2 2020.716 1914.209 2005.084 2058.612 2074.126 1879.213 1732.478 2291.169\n3 2805.135 2819.958 2763.979 2772.032 2927.637 2908.879 2836.491 2823.112\n4 1870.514 2407.630 2253.669 2162.562 2255.998 2237.350 2648.483 1944.208\n5 3029.123 2974.476 2970.545 2990.242 2992.420 3078.445 2770.413 2800.558\n6 1267.159 1760.098 1280.491 1329.725 1154.004 1123.026 1410.267 1291.729\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3290.583 3239.042 3348.059 3261.146 3279.058 3426.484 3033.712 3151.858\n2 2205.478 1876.855 1610.159 1939.986 2160.046 2018.486 1900.499 2043.437\n3 2864.290 2617.414 2732.841 2610.398 2830.679 2907.674 2600.704 2781.724\n4 2063.241 1932.238 2253.504 1570.465 2039.097 1920.537 2309.934 2458.009\n5 2779.279 2906.531 2697.709 3028.357 2876.933 2979.835 2551.114 2614.471\n6 1004.459 1324.289 1113.335 1551.421 1340.469 1349.574 1413.712 1400.158\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3177.720 3291.221 3464.818 3644.087 3456.118 2881.228 3116.432 3588.826\n2 2101.833 1945.291 1864.581 1977.484 2015.946 1913.024 1953.299 1800.475\n3 2683.924 2688.056 2805.308 2999.247 2784.005 2483.398 2628.892 2839.440\n4 1935.354 1994.075 2208.503 2148.211 1828.009 2293.561 2101.023 2037.527\n5 2836.905 2936.812 3007.180 3147.263 3151.404 2492.879 2697.954 3172.227\n6 1201.879 1131.874 1137.150 1001.981 1461.394 1360.225 1244.491 1405.035\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3206.702 3388.859 3204.100 3290.695 3255.226 3237.015 3389.660 3108.571\n2 1956.428 1872.113 1973.996 1879.639 1812.541 2003.528 1971.644 1730.641\n3 2712.990 2846.067 2603.526 2711.583 2637.849 2715.285 2819.501 2510.854\n4 2240.876 2403.478 1623.719 1892.393 2034.402 1993.921 2248.292 2112.340\n5 2761.126 2835.862 2862.690 2879.217 2932.218 2926.265 2961.393 2723.526\n6 1133.233 1121.644 1026.928 1106.129 1338.606 1267.510 1392.270 1271.563\n     .pred    .pred    .pred    .pred     .pred    .pred    .pred    .pred\n1 3327.865 3279.263 3396.865 3254.427 3198.7349 3123.245 3283.872 3362.828\n2 1905.805 1957.005 2012.835 2047.413 2014.6689 1927.224 1896.419 1874.129\n3 2647.494 2753.037 2892.934 2708.856 2747.7851 2584.482 2718.033 2779.166\n4 1871.568 2164.963 2177.012 2072.873 2396.7052 1891.979 2136.507 2209.853\n5 3057.123 2848.405 2884.723 2808.679 2660.1582 2860.423 2937.784 2947.420\n6 1184.105 1194.788 1373.848 1060.498  739.2297 1459.508 1258.995 1298.215\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3233.223 3255.355 3106.795 3291.726 3322.926 3205.659 3183.284 3065.686\n2 1929.081 1892.142 2094.087 2107.484 2022.892 1880.618 1812.208 1885.834\n3 2694.976 2664.674 2673.665 2823.126 2727.687 2664.412 2589.072 2571.694\n4 2531.403 1976.781 2250.481 1993.606 1831.285 2143.757 1981.362 2057.087\n5 2837.764 2939.352 2705.968 2920.505 3020.941 2755.987 2875.404 2591.557\n6 1331.960 1290.219 1295.225 1203.504 1372.790 1250.935 1445.903 1014.681\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3124.018 3114.584 3222.566 3151.580 3181.882 2990.583 3477.699 3237.388\n2 1701.797 1835.252 2204.914 1910.976 2177.969 1948.577 2018.701 1901.342\n3 2564.645 2637.838 2696.762 2625.761 2748.772 2409.891 2831.605 2753.862\n4 2274.285 2199.951 1974.590 2153.944 1885.585 1837.252 1924.120 2219.820\n5 2747.400 2559.262 2964.012 2787.621 2787.012 2801.508 3168.550 2771.758\n6 1558.398 1011.824 1232.789 1414.425 1196.562 1458.291 1407.457 1325.072\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3306.895 3232.381 3649.330 3466.330 3480.119 3134.046 3311.321 3391.113\n2 2173.457 2029.949 1647.608 1901.991 2069.533 2044.653 2062.244 1940.044\n3 2830.174 2706.086 2997.099 2869.864 2824.541 2673.921 2795.254 2814.728\n4 2272.979 1924.746 2314.376 2228.551 1917.872 2171.968 1998.989 2195.543\n5 2887.418 2884.302 3060.421 3008.292 3142.485 2719.603 2957.028 2930.507\n6 1082.784 1374.857 1226.388 1297.366 1206.329 1001.629 1323.175 1291.272\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3224.028 3319.898 3276.477 3223.792 3113.464 3289.395 3228.487 3366.775\n2 2140.746 1952.476 1933.274 1934.686 1771.672 1881.735 2028.225 1973.248\n3 2718.889 2669.559 2717.367 2752.846 2608.135 2750.055 2660.976 2757.841\n4 1844.029 1899.130 1949.404 2310.482 2212.896 2159.356 2039.473 1812.366\n5 2920.171 2919.860 2859.291 2682.038 2663.284 2750.908 2846.459 2989.784\n6 1382.169 1152.593 1350.045 1093.637 1325.119 1062.450 1203.976 1257.644\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3361.098 3291.146 3292.273 3321.307 3311.805 3366.603 3311.223 3207.041\n2 1853.947 1758.151 2024.351 1903.389 1940.133 2041.348 1794.285 1936.241\n3 2736.293 2727.588 2773.263 2640.860 2707.287 2868.014 2721.015 2706.894\n4 1998.333 2205.734 2335.061 1878.765 1881.994 2246.218 2136.639 1907.433\n5 2991.578 2809.373 2790.993 3137.671 2944.144 2896.844 2926.334 2744.139\n6 1195.271 1204.511 1242.635 1409.774 1184.094 1189.803 1333.191 1280.289\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3277.802 3389.794 3086.957 3332.001 3407.714 3424.824 3194.328 3203.241\n2 2313.125 1925.189 1740.780 2065.568 1873.620 2181.138 1805.269 2024.904\n3 2776.726 2810.727 2527.055 2804.174 2805.508 2897.491 2656.190 2705.364\n4 1898.523 2282.949 1889.937 2260.474 2061.654 1940.724 2143.024 1878.251\n5 3047.515 2925.237 2730.916 2807.000 2969.877 2972.068 2709.668 2836.237\n6 1387.976 1192.089 1215.470 1082.707 1222.911 1241.769 1197.384 1267.673\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3197.624 3337.011 3153.466 3586.352 3200.171 3192.183 3290.830 3326.416\n2 1815.282 2042.972 1816.881 2032.066 1878.628 1876.578 1982.446 1938.143\n3 2599.075 2720.908 2636.961 2926.028 2610.456 2663.062 2775.209 2740.928\n4 2155.184 2345.112 2127.096 1933.199 1740.887 2158.739 2035.466 2268.515\n5 2759.124 2990.725 2620.432 3170.107 2842.384 2892.854 2859.097 3024.425\n6 1064.789 1139.322 1203.997 1175.791 1149.740 1478.548 1596.803 1437.490\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3321.223 3183.496 3381.304 3235.906 3149.020 3002.248 3153.388 3649.345\n2 1833.146 1970.804 1907.338 2012.384 2022.696 1822.030 1877.755 2078.562\n3 2747.932 2662.403 2863.018 2736.757 2694.263 2508.451 2660.898 2937.206\n4 2206.772 2406.743 2170.507 2182.824 2083.160 2233.602 2133.364 2125.634\n5 2818.083 2708.820 2946.860 2804.472 2790.095 2606.618 2640.841 3302.412\n6 1268.754 1001.703 1508.630 1269.259 1378.851 1294.612 1000.604 1209.680\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3473.622 3526.491 3380.947 3220.522 3547.694 3651.935 3139.032 3254.397\n2 2124.916 2047.532 1908.890 1989.495 1929.887 1854.294 1955.594 2021.653\n3 2862.703 3042.915 2776.050 2660.093 2907.759 2941.584 2531.672 2756.741\n4 1885.587 2352.755 2190.142 1845.221 2540.017 2150.269 1951.429 2038.661\n5 3107.893 2988.279 3009.164 2869.899 3107.179 3276.266 2942.975 2914.467\n6 1236.863 1360.973 1192.276 1164.341 1390.220 1410.776 1487.866 1576.865\n     .pred    .pred    .pred    .pred    .pred     .pred    .pred    .pred\n1 3340.153 3251.374 3223.981 3404.954 3285.701 3348.6342 2909.897 3299.555\n2 1840.032 1984.948 2045.929 2016.772 1979.926 2064.2495 2030.651 1923.788\n3 2758.520 2660.266 2617.252 2827.595 2807.143 2776.0662 2502.660 2736.826\n4 2262.678 1924.139 1820.241 1872.634 2340.418 2217.6426 2032.757 2071.504\n5 2942.180 3027.979 3012.250 3052.835 2795.901 2916.5522 2653.117 2891.556\n6 1232.861 1659.851 1351.555 1384.434 1182.877  834.5039 1718.452 1188.713\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred     .pred\n1 3329.281 3252.904 3029.572 3415.477 3385.156 3365.828 3583.485 3192.8279\n2 1789.613 1824.269 1890.373 1992.440 2067.744 1897.487 2033.921 2054.4582\n3 2702.399 2714.059 2517.598 2842.801 2889.061 2830.598 3014.262 2700.9124\n4 2190.850 1998.930 2403.472 2114.286 2209.414 2237.406 1933.172 2224.5132\n5 2865.796 2844.929 2730.243 3010.559 2885.441 2885.542 3108.518 2643.6663\n6 1084.473 1142.635 1474.845 1245.396 1303.172 1225.448 1249.074  675.0844\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3422.939 3397.742 3418.949 3124.214 3403.922 3370.089 3070.079 3118.083\n2 2091.626 1852.798 1986.364 2156.317 1890.350 1910.257 1816.599 2028.089\n3 2862.866 2745.432 2857.383 2665.282 2778.298 2801.250 2449.396 2712.425\n4 2018.333 1903.729 2157.043 1837.015 1946.295 2049.822 1678.615 2176.937\n5 2955.425 2975.826 3008.036 2776.393 2977.108 2886.486 2853.248 2695.046\n6 1148.381 1170.048 1367.590 1219.944 1077.052 1204.868 1193.698 1348.797\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3400.583 3332.521 3213.278 3360.964 3528.366 3252.285 3370.269 3318.225\n2 2048.252 1934.278 1672.726 1878.002 1765.086 1885.794 1786.913 2056.968\n3 2893.699 2693.946 2557.205 2759.018 2814.937 2709.832 2731.939 2819.433\n4 2073.543 1627.797 1953.908 2055.718 2046.505 2188.792 1987.469 2046.111\n5 3037.551 3097.122 2846.994 2987.507 3116.628 2747.917 2977.212 2900.232\n6 1491.663 1427.840 1320.431 1543.043 1493.953 1109.556 1348.166 1272.010\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3081.741 3440.383 3312.909 3364.214 3242.824 3485.980 3197.065 3503.194\n2 1916.246 2023.702 2067.307 2006.488 1844.614 1594.693 2088.119 1989.789\n3 2504.229 2836.162 2774.971 2796.725 2681.267 2753.952 2741.437 2794.847\n4 2202.010 1861.932 2047.286 2193.018 1940.260 1850.393 1765.072 1769.788\n5 2815.796 3005.500 2889.850 2925.032 2815.952 3114.408 2854.312 3256.539\n6 1356.329 1439.073 1261.029 1317.871 1320.641 1338.095 1570.372 1371.208\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3412.500 3418.250 3243.327 3118.489 3315.909 3365.346 3664.944 3269.607\n2 1732.900 2131.068 2093.338 1814.160 1956.391 2121.281 1611.913 1906.718\n3 2712.590 2870.380 2750.776 2539.041 2783.002 2755.454 2944.456 2785.133\n4 1974.237 2150.142 2235.306 1771.386 2086.197 1905.311 2388.048 2341.879\n5 3007.165 2952.600 2822.481 2795.675 2851.018 3082.810 3148.785 2720.848\n6 1407.934 1270.350 1256.473 1338.392 1447.303 1341.736 1236.482 1127.590\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3135.579 3617.679 3721.580 3530.434 3165.013 3118.937 3439.019 3273.076\n2 1972.347 1909.305 1947.540 1863.466 1874.902 1919.484 1806.287 1829.669\n3 2677.684 2860.420 2977.279 2928.739 2642.519 2642.763 2724.628 2728.802\n4 2150.841 1945.262 2016.552 2035.413 2259.856 2323.809 2117.114 2455.003\n5 2761.420 3230.966 3333.144 3024.435 2703.341 2767.434 3000.106 2734.064\n6 1372.457 1132.886 1225.449 1327.288 1331.571 1322.762 1272.851 1264.471\n     .pred    .pred    .pred     .pred    .pred    .pred    .pred    .pred\n1 3268.531 3326.705 3411.780 3312.8271 3301.616 3473.527 3641.128 3324.073\n2 1943.407 2025.196 1926.257 2141.8695 2060.997 1892.373 2068.471 1895.681\n3 2709.718 2878.104 2861.929 2811.2432 2700.970 2917.063 3044.343 2777.840\n4 1953.527 2235.283 2255.318 2099.5823 1658.157 2268.822 1988.607 2091.434\n5 2885.491 2854.590 2974.277 2843.3438 2952.660 2984.893 3189.040 2831.940\n6 1160.343 1438.654 1148.060  907.1611 1114.780 1355.961 1206.864 1311.151\n     .pred    .pred    .pred    .pred    .pred     .pred    .pred    .pred\n1 3273.431 3225.583 3463.636 3273.843 3406.196 3609.6361 3432.316 3290.540\n2 2145.431 1919.716 1927.612 1995.995 1930.479 1972.5344 1718.558 2020.028\n3 2830.862 2662.696 2841.239 2629.320 2767.038 2942.6035 2817.744 2697.176\n4 2433.468 1921.820 2110.879 1676.503 1873.606 2166.7281 2410.944 1997.008\n5 2870.088 2815.048 3037.813 3096.575 2969.818 3043.7883 2904.982 2977.395\n6 1252.714 1208.847 1197.392 1399.814 1346.052  941.3002 1050.408 1360.248\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3048.306 3133.910 3310.708 3338.565 3397.537 3417.270 3245.836 3079.157\n2 1947.313 1927.785 1909.461 1991.076 1963.140 1823.263 2105.277 2016.464\n3 2672.414 2587.520 2765.139 2786.891 2756.345 2868.780 2770.091 2643.016\n4 2198.612 2123.332 2062.536 2447.076 2007.691 2294.840 2258.536 2168.469\n5 2497.725 2762.986 2952.935 2856.283 3022.173 2911.631 2939.144 2641.478\n6 1035.215 1247.414 1302.701 1088.628 1244.911 1433.177 1386.944 1295.473\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3249.905 3270.920 3562.525 3137.422 3073.579 3294.859 3325.770 3106.880\n2 1899.890 1946.310 1951.297 2017.239 2051.598 1994.570 1973.933 2028.147\n3 2684.408 2760.694 2817.043 2645.078 2675.095 2697.785 2706.645 2553.510\n4 2004.227 2071.353 1681.454 2059.158 2580.256 2074.446 1537.114 2284.934\n5 2878.539 2829.864 3261.994 2764.827 2706.430 2954.281 3029.994 2819.094\n6 1267.268 1181.901 1225.295 1174.199 1641.796 1092.388 1149.223 1281.523\n      .pred    .pred    .pred     .pred    .pred    .pred    .pred    .pred\n1 3401.6242 3261.451 3267.082 3302.7784 3363.718 3188.647 3460.407 3335.513\n2 1880.5720 1988.521 1635.421 2046.5651 2024.670 1958.990 2105.340 1876.957\n3 2812.8364 2668.531 2628.042 2728.9692 2749.878 2650.623 2869.103 2774.089\n4 2292.5697 2047.560 2159.137 1930.9299 1938.880 1905.423 1813.287 2249.946\n5 2779.2321 2864.187 2883.086 2927.6740 3082.237 2861.009 3123.336 2772.695\n6  963.8821 1033.350 1626.665  917.3093 1400.595 1375.748 1199.480 1094.552\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3468.673 3297.328 3524.116 3206.811 3290.230 3500.417 3153.936 3168.423\n2 2041.619 2134.881 1878.225 1873.665 2041.741 2105.118 1731.592 1876.360\n3 2895.636 2865.942 2843.255 2700.873 2832.716 2850.677 2651.391 2580.770\n4 2030.120 2292.949 2065.157 2115.149 2206.602 1988.844 2281.358 2126.531\n5 3058.583 2742.690 3168.835 2759.876 2806.715 3194.722 2732.518 2830.303\n6 1283.447 1006.416 1301.613 1176.382 1266.879 1441.973 1416.684 1461.697\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3382.970 3282.308 3248.103 3205.907 3512.871 3241.187 3399.446 3443.160\n2 1945.952 1886.474 2061.496 1909.270 1905.682 1954.669 1704.812 1913.094\n3 2764.780 2770.086 2768.248 2613.316 2841.657 2740.860 2812.774 2811.954\n4 1906.739 2439.154 1984.101 2238.318 2206.091 2599.738 2217.528 2059.020\n5 3049.754 2836.161 2806.978 2827.836 3090.355 2794.131 2810.121 2964.360\n6 1385.888 1492.142 1274.786 1300.141 1222.845 1214.205 1228.810 1115.854\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3392.789 3482.934 3151.484 3226.155 3188.562 3587.366 3268.611 3264.926\n2 1756.551 1901.115 1860.825 1993.025 1960.449 2129.817 1954.346 2033.099\n3 2747.248 2888.207 2589.980 2661.717 2669.365 2925.306 2693.773 2859.460\n4 2144.859 2418.188 2279.363 1963.696 1878.350 1964.673 2047.968 2166.685\n5 2909.918 2978.734 2825.799 2841.892 2854.615 3249.997 2823.930 2703.915\n6 1174.362 1314.203 1504.306 1232.848 1169.081 1359.232 1216.379 1261.351\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3113.748 3330.572 3335.926 3497.031 3437.557 3291.062 3051.172 3413.576\n2 1885.492 1979.124 1906.025 1941.435 1834.055 2000.090 1876.850 1669.664\n3 2640.027 2732.099 2699.946 2904.179 2850.858 2738.637 2577.077 2775.531\n4 2271.210 1937.542 2014.355 2048.017 2197.758 2092.671 2187.856 2209.917\n5 2625.341 2885.384 2999.633 3022.271 2961.172 2808.628 2648.097 2965.008\n6 1167.436 1107.459 1161.603 1440.147 1176.900 1365.829 1301.030 1309.047\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3278.336 3356.731 3406.930 3392.744 3369.273 3331.483 3429.442 3166.889\n2 2017.157 1850.561 1883.572 1900.754 2162.316 1894.093 1969.497 1787.317\n3 2772.275 2713.866 2742.826 2835.079 2812.477 2769.965 2832.899 2674.437\n4 1967.401 2018.689 1962.702 2215.048 1951.168 1893.313 2023.017 2316.904\n5 2818.880 2957.571 2975.099 2955.432 3163.701 2910.541 3060.913 2643.728\n6 1321.716 1189.265 1059.827 1440.972 1604.713 1451.909 1319.990 1354.091\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3056.801 3298.588 3571.221 3101.055 3167.338 3387.468 3375.394 3306.630\n2 1784.987 1840.168 1988.518 1953.571 1744.355 2039.870 1963.344 1938.092\n3 2505.987 2712.203 2957.015 2596.960 2657.814 2801.084 2778.315 2699.756\n4 1754.230 2308.704 2289.506 1998.952 2222.738 2184.827 2450.839 2259.990\n5 2780.009 2948.727 3221.609 2779.047 2678.298 3066.069 3002.957 2829.609\n6 1365.695 1585.214 1483.713 1214.293 1249.735 1367.614 1255.694 1423.660\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3313.723 3122.065 3178.540 2985.621 3148.346 3235.334 3325.892 3205.641\n2 2155.325 1839.749 1812.635 1996.328 1995.337 1781.999 2005.229 1946.706\n3 2760.908 2624.941 2545.449 2493.546 2626.479 2594.668 2721.525 2599.053\n4 1695.858 2248.896 1931.102 2038.035 1807.421 2109.527 2108.000 1701.882\n5 3131.543 2679.097 2846.589 2654.474 2781.033 2829.501 3034.369 2912.924\n6 1670.760 1279.712 1444.218 1110.986 1183.942 1158.452 1519.407 1224.199\n     .pred    .pred    .pred    .pred     .pred    .pred     .pred    .pred\n1 3015.333 3357.377 3160.201 3130.930 3323.8133 3378.966 3231.6046 3146.329\n2 1969.249 1810.810 2170.582 1962.867 2159.5345 2032.268 2183.8749 1915.260\n3 2476.157 2809.173 2659.416 2593.300 2770.4053 2785.383 2813.4207 2652.469\n4 2099.585 2273.820 1961.902 1732.188 1788.4167 2188.666 2183.4913 2357.133\n5 2920.385 2796.125 2846.954 2825.888 2933.3569 3110.941 2698.8696 2760.927\n6 1681.513 1338.710 1248.327 1435.603  950.6452 1477.502  981.9356 1160.255\n     .pred    .pred     .pred    .pred    .pred    .pred    .pred    .pred\n1 3175.595 3186.383 3255.4358 3198.679 3156.421 3141.472 3249.198 3300.313\n2 1827.184 2072.048 1971.4262 1708.036 2007.182 1877.121 1920.771 1786.267\n3 2661.057 2658.851 2642.2762 2590.339 2718.340 2656.960 2617.541 2832.293\n4 2332.024 1917.946 1809.9902 1895.969 2277.332 2316.629 1971.686 2412.864\n5 2676.863 2914.331 2935.8903 2828.332 2751.548 2687.421 2876.408 2757.891\n6 1134.025 1374.933  993.8275 1299.543 1395.966 1247.941 1278.688 1438.191\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred     .pred\n1 3314.301 3351.756 3260.004 3309.380 3101.752 3608.096 3215.856 3362.1087\n2 1821.888 1911.835 2047.696 2086.472 1859.649 1965.839 2108.489 2117.8654\n3 2749.569 2814.402 2711.193 2782.242 2536.729 2936.913 2567.903 2741.3834\n4 2300.128 2173.919 1848.493 1880.490 2055.180 2330.431 1725.941 1908.8310\n5 2838.670 2899.590 2893.640 2907.427 2812.644 3157.754 3022.068 3022.2013\n6 1243.580 1248.389 1238.568 1312.190 1385.492 1561.383 1362.097  949.2771\n     .pred    .pred     .pred    .pred     .pred    .pred    .pred    .pred\n1 3225.676 3328.041 3303.7015 3061.456 3268.1936 3281.156 3219.777 3238.570\n2 2131.980 2067.804 1873.5508 2005.393 2027.4187 2053.732 1893.724 2163.276\n3 2738.181 2762.680 2672.0272 2626.432 2722.8592 2766.826 2665.831 2605.889\n4 2049.805 2125.127 1714.0747 2102.726 2084.3648 2007.091 1797.866 1468.266\n5 2811.245 2911.383 2875.8924 2803.440 2804.9759 2954.669 2853.541 3162.627\n6 1419.206 1207.715  986.5859 1674.396  959.2649 1514.946 1444.092 1600.148\n     .pred    .pred    .pred    .pred    .pred     .pred    .pred    .pred\n1 3354.198 3206.210 3161.775 3278.378 3067.154 3522.0876 3402.276 3326.583\n2 2090.271 1841.160 1892.438 1749.437 1837.297 1848.1380 1977.577 1908.233\n3 2797.030 2629.948 2626.598 2681.331 2545.218 2867.2440 2807.304 2788.381\n4 1903.996 2195.197 2188.512 2294.763 1813.536 2475.5693 2144.334 1962.855\n5 2947.739 2789.993 2677.967 2771.715 2773.336 2991.0618 2995.691 2826.830\n6 1072.715 1424.336 1249.417 1434.519 1654.742  918.1852 1293.720 1120.255\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3263.733 3070.870 3340.776 3214.221 3289.163 3177.145 3422.525 3047.796\n2 2081.861 2132.916 2204.268 2128.298 2206.817 2259.877 1843.701 1903.352\n3 2761.518 2578.425 2781.819 2715.120 2747.442 2796.224 2806.446 2554.612\n4 2185.410 1989.371 2156.992 1999.836 1823.638 2268.811 2111.333 2014.252\n5 2827.601 2902.443 3093.273 2822.421 2963.852 2862.868 3040.025 2649.826\n6 1122.179 1370.904 1279.095 1157.337 1153.375 1518.805 1265.582 1250.724\n     .pred    .pred    .pred    .pred    .pred    .pred     .pred    .pred\n1 3131.164 3291.935 3478.762 3074.839 3092.206 3516.926 3538.6483 3229.430\n2 2178.644 2070.576 2057.406 1964.371 2319.326 1822.524 2050.7159 2029.857\n3 2703.898 2943.434 2885.109 2565.449 2640.794 2943.461 2868.0730 2626.335\n4 2036.108 2694.199 2137.507 2058.791 2265.369 2476.108 2028.4900 1736.450\n5 2864.477 2668.845 3062.183 2682.664 2755.396 2925.107 3130.1030 3005.981\n6 1419.568 1482.185 1126.660 1168.710 1362.450 1087.855  989.6687 1570.651\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3168.440 3307.233 3213.229 3238.385 3073.582 3283.131 3439.881 3252.625\n2 1997.253 2165.960 1927.019 2027.602 1820.486 1903.698 1995.661 2005.347\n3 2803.291 2716.559 2754.234 2641.763 2677.750 2692.389 2838.046 2646.620\n4 2436.546 1841.788 2298.500 1730.730 2324.085 2142.944 2105.987 1916.920\n5 2583.492 3026.027 2649.580 3005.117 2567.247 2907.439 3020.609 2935.960\n6 1247.962 1200.447 1024.378 1349.279 1516.028 1071.276 1126.471 1307.636\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3193.391 3507.591 3373.537 3215.552 3224.269 3344.333 3470.430 3441.963\n2 2173.173 1780.129 1981.718 1898.111 1854.021 1937.269 1917.792 2024.552\n3 2683.553 2776.711 2710.657 2647.946 2629.075 2784.925 2885.764 2843.905\n4 2218.374 1960.136 1492.139 2308.230 1921.482 2510.179 2127.659 2211.492\n5 2813.008 3133.965 3103.349 2983.763 2827.074 2863.638 2946.317 2994.760\n6 1114.418 1391.025 1342.256 1603.742 1296.274 1090.575 1269.490 1256.276\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3093.808 3028.290 3265.122 3416.547 3428.037 3293.448 3359.332 3444.667\n2 2437.180 1986.809 1900.848 1680.068 2012.327 2018.050 1977.777 1805.243\n3 2723.115 2531.201 2718.777 2707.828 2826.393 2726.437 2730.207 2823.481\n4 1920.126 1965.285 2252.359 2173.172 2094.614 2018.875 2160.277 2000.120\n5 2755.242 2720.656 2791.762 2972.487 3055.618 2909.455 2914.407 2973.932\n6 1212.184 1644.067 1332.870 1127.057 1471.184 1133.965 1122.413 1361.313\n     .pred    .pred    .pred     .pred    .pred    .pred    .pred    .pred\n1 3486.644 3140.010 3213.621 3354.0035 3297.317 3223.842 3373.382 3540.028\n2 1802.435 1923.381 1871.558 2222.2917 2073.871 2053.712 1754.122 2047.450\n3 2841.338 2609.409 2620.045 2968.4238 2758.302 2755.653 2744.117 2887.969\n4 2020.472 2054.251 2135.273 2247.8268 1984.744 2268.491 2076.475 1856.466\n5 3072.486 2828.581 2906.647 2790.0781 2946.346 2728.933 2987.848 3251.260\n6 1346.265 1493.274 1273.452  989.5642 1169.656 1218.530 1439.967 1471.737\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3384.443 3350.517 2967.853 3392.599 3347.842 3187.781 3379.711 3311.942\n2 1915.006 1872.111 1880.850 1796.293 1869.980 2057.340 1858.244 1681.869\n3 2821.325 2772.553 2497.789 2706.990 2776.117 2673.750 2870.655 2690.813\n4 2158.176 2133.907 2285.973 2025.613 2087.020 2052.406 2322.021 2196.556\n5 2920.249 2967.408 2614.579 2953.536 2922.148 2812.717 2852.528 2805.342\n6 1035.385 1493.241 1442.038 1171.369 1232.446 1227.642 1534.998 1021.552\n     .pred    .pred    .pred    .pred    .pred    .pred     .pred    .pred\n1 3287.424 3381.424 3329.125 3540.160 3070.348 3394.414 3298.8948 3355.588\n2 1815.540 1872.308 2080.061 1931.947 2102.358 1999.661 1848.0655 1830.175\n3 2757.693 2735.005 2785.418 2806.174 2576.162 2819.822 2764.4646 2800.205\n4 2224.113 1974.956 2084.023 1959.862 2119.925 2264.272 2258.9069 2287.305\n5 2849.794 2971.364 3004.578 3184.624 2878.361 2954.450 2741.8944 2829.755\n6 1154.871 1110.576 1171.669 1380.802 1286.731 1229.105  828.1819 1276.691\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3439.107 3469.685 3186.290 3047.342 3247.250 3362.984 2992.223 3451.605\n2 1877.793 1853.598 1964.283 1820.135 2023.088 1794.071 1927.715 1982.363\n3 2744.885 2860.864 2620.586 2641.377 2745.569 2693.409 2525.091 2851.156\n4 1730.967 2356.381 2123.080 2399.195 2006.628 2064.387 2011.335 2196.746\n5 3113.136 2960.225 2858.182 2427.629 2841.282 2975.203 2620.829 2994.122\n6 1339.549 1311.691 1355.626 1070.349 1458.547 1281.224 1452.677 1373.363\n      .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3234.3931 3400.190 3358.648 3342.858 3349.668 3196.918 3351.614 3294.322\n2 2002.6873 1932.567 2043.320 2072.089 1932.528 2175.473 2073.055 1906.640\n3 2768.4170 2798.293 2829.824 2813.647 2923.007 2701.541 2807.089 2854.311\n4 2151.6998 2320.944 2082.710 1842.748 2311.111 1940.845 1825.868 2469.539\n5 2729.0335 2988.813 2912.612 3007.129 2733.446 2953.118 2849.637 2705.932\n6  960.0236 1361.744 1273.120 1440.100 1318.701 1476.878 1014.386 1303.532\n     .pred    .pred    .pred    .pred    .pred     .pred    .pred    .pred\n1 3400.322 2968.760 3406.228 3181.182 3643.512 3344.5465 3162.800 3142.367\n2 1942.123 1928.648 2010.062 1681.510 1808.331 2292.8134 1990.679 2114.288\n3 2763.758 2539.981 2698.684 2569.736 2986.437 2777.0653 2689.877 2718.638\n4 2191.261 2201.345 1495.500 1919.657 2272.918 1817.0921 2004.405 1807.780\n5 3043.914 2602.373 3205.059 2808.346 3167.770 2999.6987 2810.546 2721.549\n6 1115.578 1291.513 1214.937 1195.476 1279.202  908.5953 1435.880 1398.288\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3290.655 3258.854 3279.364 3390.226 3281.044 3370.037 3254.895 3191.221\n2 1937.843 1949.406 1939.016 1879.996 1870.782 1936.433 2204.136 1876.802\n3 2825.946 2689.193 2714.893 2842.707 2689.906 2797.185 2773.576 2732.712\n4 2764.656 1873.725 1932.896 2281.359 1973.938 2004.577 2217.176 2198.868\n5 2759.389 2967.050 2914.980 2989.156 3001.978 3017.148 2885.240 2614.385\n6 1362.353 1509.758 1449.023 1320.573 1576.334 1477.899 1313.292 1320.219\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3071.621 3291.648 3535.984 3234.852 3156.608 3374.998 3170.895 3244.716\n2 1730.098 2022.951 1972.520 2141.796 1896.897 1854.981 1888.664 2109.376\n3 2557.168 2703.591 2934.058 2680.107 2648.999 2743.672 2689.672 2728.498\n4 2127.068 1698.326 2004.075 2126.385 2065.932 2045.043 2235.127 1953.238\n5 2610.406 3047.780 3054.354 2916.234 2773.826 2941.614 2734.679 2973.949\n6 1311.610 1257.976 1139.584 1318.571 1321.413 1366.974 1356.811 1361.945\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3291.699 3707.374 3229.592 3103.271 3291.317 3191.750 3309.249 3071.554\n2 1843.640 1884.681 2007.453 1862.734 1822.936 1812.517 1854.523 1959.000\n3 2717.002 2937.992 2730.422 2667.812 2728.244 2677.030 2670.326 2533.054\n4 2368.210 2278.391 2039.032 2267.343 2028.509 2235.904 1761.570 1986.484\n5 2827.900 3215.984 2884.181 2604.564 2729.632 2679.720 3045.179 2767.903\n6 1244.012 1075.658 1607.591 1193.962  928.138 1309.271 1479.154 1457.790\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3120.908 3417.794 3292.468 3267.499 3344.592 3330.609 3155.180 3338.629\n2 2105.744 1905.415 1985.379 1832.584 2151.130 1924.748 1937.743 1924.120\n3 2632.252 2778.170 2862.734 2710.710 2804.412 2731.176 2645.888 2891.489\n4 1994.205 2501.935 2264.663 2126.047 2030.762 1989.502 1993.287 2343.427\n5 2764.386 3037.403 2732.099 2889.053 3045.577 2967.045 2684.463 2813.750\n6 1365.335 1393.877 1371.810 1405.007 1418.054 1322.135 1153.227 1122.048\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3238.020 3306.617 3492.809 3512.320 3196.535 3414.286 3131.226 3174.552\n2 2017.477 1969.387 1829.540 1924.886 1749.618 1616.616 2123.341 1710.822\n3 2668.444 2697.417 2846.755 2824.451 2625.680 2720.373 2658.082 2579.532\n4 2185.902 2281.154 2057.380 1594.916 2133.172 1933.802 1938.727 2154.891\n5 2842.805 2894.262 3055.310 3147.906 2821.728 3035.569 2707.954 2682.424\n6 1210.422 1158.642 1518.695 1197.926 1353.728 1513.810 1163.724 1034.881\n     .pred    .pred    .pred    .pred     .pred    .pred    .pred    .pred\n1 3292.989 3129.305 3079.428 3510.833 3385.5744 3412.890 3253.126 3271.383\n2 1751.493 1780.628 2052.594 1950.687 2032.3968 1756.323 1846.715 1734.008\n3 2723.081 2537.193 2588.112 2850.245 2774.9058 2814.514 2678.194 2699.859\n4 2338.875 1899.096 1908.836 1718.934 1902.6554 2273.839 2191.934 2103.427\n5 2838.645 2749.471 2738.695 3021.370 3008.3714 2866.071 2825.425 2903.199\n6 1511.187 1149.451 1430.469 1192.513  857.6952 1137.051 1233.325 1667.819\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3052.923 3119.840 3194.657 3389.523 3421.806 3108.668 3360.254 3487.986\n2 1769.231 1885.121 1953.465 1896.312 2019.842 2042.401 1984.328 1788.690\n3 2470.396 2638.176 2661.704 2805.738 2784.319 2631.320 2749.837 2903.693\n4 1892.111 2224.540 1800.486 1900.857 1963.830 1814.225 1889.841 2335.603\n5 2740.364 2644.225 2817.753 2939.181 3068.312 2747.575 2985.487 2876.054\n6 1455.419 1220.742 1384.170 1269.573 1163.435 1342.224 1072.386 1098.646\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3058.642 3215.451 3291.231 3216.875 3095.325 3530.811 3435.137 3289.214\n2 2020.826 1834.391 1938.195 1946.281 1859.441 1835.395 1727.796 2026.995\n3 2608.482 2649.501 2667.748 2731.902 2592.245 2748.870 2795.856 2817.319\n4 2376.018 1805.969 2067.968 2050.900 1880.989 1660.104 2183.302 1996.579\n5 2823.808 2832.423 2996.694 2708.706 2707.361 3348.682 2978.949 2751.094\n6 1637.272 1317.003 1385.174 1129.759 1284.783 1547.821 1429.298 1149.267\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3301.076 3250.980 3210.215 3538.340 3398.360 3449.456 3129.335 3491.422\n2 1792.763 1679.782 2025.528 1996.800 1897.311 2029.407 1831.351 1839.237\n3 2686.827 2609.628 2719.714 2932.661 2798.630 2865.033 2492.550 2856.238\n4 2094.762 1985.696 1853.354 1950.580 2353.483 2169.136 2050.686 2234.268\n5 2797.996 2854.187 2773.215 3167.845 2953.876 3112.268 2962.202 2984.443\n6 1243.605 1415.056 1303.773 1332.131 1233.558 1468.514 1680.992 1300.311\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3263.559 3301.721 3351.568 3241.248 3100.688 3459.138 3194.706 3298.884\n2 1935.126 1813.496 1977.905 1972.466 2129.865 1773.669 1912.128 1854.452\n3 2671.122 2735.873 2732.479 2663.990 2714.172 2825.768 2573.749 2767.541\n4 1972.969 2090.852 2155.681 2117.606 2237.734 2349.897 1790.850 2073.308\n5 2865.681 2913.288 2940.126 2889.220 2645.321 2881.962 2894.157 2940.878\n6 1139.379 1510.572 1210.729 1314.142 1070.813 1388.231 1298.473 1327.773\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3384.826 3495.785 3458.575 3153.012 3489.584 3251.259 3211.498 3236.234\n2 1874.711 1988.992 1851.126 1959.096 1865.902 2059.191 1882.382 1896.215\n3 2853.876 2908.431 2775.427 2606.624 2824.405 2742.570 2564.516 2747.846\n4 2103.362 2321.057 1971.133 1899.736 1748.930 1873.541 1946.816 2277.761\n5 2891.901 3027.943 3092.697 2863.230 3029.411 2873.160 2936.179 2785.584\n6 1368.731 1100.641 1230.891 1553.886 1091.553 1226.124 1224.934 1275.673\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3676.776 3413.499 3351.733 3250.165 3557.510 3457.392 3379.810 3199.761\n2 2094.136 1698.291 2166.024 2076.401 1908.383 2007.965 1865.361 1783.099\n3 2981.046 2850.420 2843.083 2674.547 2913.339 2839.392 2757.076 2610.500\n4 2090.402 2463.006 2028.921 2054.702 1968.977 2212.043 1828.993 1965.326\n5 3257.157 2858.264 2978.294 2988.759 3215.373 3003.982 2980.556 2812.050\n6 1089.652 1369.380 1238.558 1345.989 1492.141 1065.446 1268.700 1102.566\n      .pred    .pred    .pred    .pred    .pred    .pred    .pred     .pred\n1 3241.7558 3268.791 3181.162 3284.822 3347.302 3153.748 3234.073 3455.2982\n2 2095.4396 1934.904 1832.018 2133.939 2041.300 1958.508 2265.161 1847.1133\n3 2715.9617 2693.414 2615.353 2794.926 2836.299 2646.950 2718.070 2775.7353\n4 1812.4489 1906.933 2007.165 2170.101 2168.535 1861.980 1989.326 1699.5992\n5 2856.8353 2881.825 2671.776 2866.255 2910.636 2722.916 2939.392 2985.1161\n6  962.9245 1305.400 1201.467 1276.175 1221.768 1297.636 1261.406  927.6372\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3238.299 3365.994 3354.062 3279.380 3341.494 3293.531 3284.411 3393.566\n2 1987.307 1862.944 1975.116 2152.970 1978.763 1733.620 1922.417 2151.623\n3 2761.089 2678.591 2780.450 2777.190 2869.918 2697.670 2785.059 2819.902\n4 2463.587 1828.824 2092.759 2193.536 2254.230 2056.303 2085.131 1755.373\n5 2741.544 2934.436 2959.200 3046.908 2774.690 2775.223 2795.887 3197.465\n6 1102.480 1056.954 1304.160 1541.795 1187.447  971.458 1288.243 1360.741\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3011.597 3379.710 3189.158 3345.356 3322.454 3218.094 3188.460 3236.722\n2 1985.255 1857.364 2001.431 1874.079 2097.006 1789.762 2118.926 2104.334\n3 2520.046 2704.679 2712.280 2797.006 2773.789 2569.043 2717.480 2698.235\n4 2148.951 2008.569 1971.978 2275.345 2178.430 1998.155 2078.845 1545.299\n5 2735.819 2981.203 2836.503 2793.910 2888.292 2888.263 2803.223 2901.695\n6 1435.836 1104.646 1351.556 1215.617 1074.868 1188.561 1196.376 1129.235\n      .pred    .pred    .pred    .pred     .pred    .pred    .pred    .pred\n1 3303.7096 3318.871 3428.297 3461.465 3482.7575 3396.867 3206.327 3229.790\n2 2314.2309 1899.048 1972.614 2060.573 1880.6658 1904.115 2217.357 2172.935\n3 2820.2714 2731.514 2720.319 2915.538 2805.4964 2865.719 2696.888 2762.006\n4 1844.0625 2119.458 1669.688 2402.002 2318.9216 2080.078 1958.798 2196.005\n5 2975.6361 2867.781 3045.960 2939.833 2960.5418 2900.601 2933.633 2878.580\n6  988.5835 1249.924 1074.657 1094.795  964.2221 1439.953 1468.107 1346.579\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3350.903 3236.086 3336.915 3517.246 3446.653 3225.554 3507.449 3332.874\n2 1987.064 1880.396 1772.818 1894.339 1931.123 2158.885 2135.941 2043.749\n3 2837.727 2755.369 2815.865 2908.697 2780.997 2742.134 2981.436 2762.826\n4 2038.586 2164.268 2250.293 2082.447 2036.653 1980.087 2090.893 2018.000\n5 2819.813 2695.571 2821.513 3047.625 3152.945 2918.660 3070.945 2923.430\n6 1306.625 1187.679 1159.663 1268.125 1484.688 1322.047 1417.745 1149.887\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3330.103 3292.556 3073.983 3530.455 3207.088 3532.874 3412.872 3460.413\n2 1901.993 2038.160 1790.288 1637.027 1883.714 2021.392 1995.621 1887.062\n3 2683.765 2799.121 2549.412 2813.469 2605.921 2980.828 2912.900 2848.516\n4 1836.795 2145.537 1874.520 2033.881 2196.812 2083.724 2223.108 2249.797\n5 2986.965 2924.846 2777.318 3095.322 2817.841 3018.491 2906.900 2951.340\n6 1145.762 1539.532 1424.731 1417.357 1206.750 1344.461 1548.942 1094.914\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3411.205 3199.407 3401.819 3416.196 3276.993 3420.743 3408.590 3431.613\n2 1974.565 1983.159 2003.853 1855.565 1963.354 1966.149 1855.070 1928.890\n3 2846.788 2683.106 2842.814 2847.525 2681.182 2746.672 2783.886 2819.917\n4 1955.077 2329.190 2090.363 2213.653 2176.104 1746.139 2304.009 2090.103\n5 2947.542 2796.730 2974.804 2987.248 2813.463 3112.783 2896.390 3046.799\n6 1337.621 1290.362 1218.921 1500.360 1047.432 1250.419 1243.528 1221.884\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3394.418 3072.502 3034.652 3310.272 3436.255 3211.700 3253.880 3274.025\n2 1741.890 1816.874 1915.383 2055.859 1979.521 2151.989 2033.834 1928.292\n3 2881.453 2535.670 2609.570 2825.434 2874.843 2708.122 2718.786 2787.526\n4 2469.605 2124.130 2440.750 2368.217 2126.231 1952.435 2189.305 2095.877\n5 2858.658 2728.465 2513.762 2695.066 2921.726 2808.793 2835.413 2821.880\n6 1340.473 1324.435 1087.830 1176.090 1207.999 1304.161 1155.235 1232.240\n     .pred     .pred    .pred     .pred    .pred    .pred    .pred    .pred\n1 3057.424 3362.8101 3195.649 3304.0237 3214.405 3083.452 3189.758 3196.284\n2 1804.191 1930.6270 1907.685 1968.3544 1854.856 1821.689 1900.916 1914.179\n3 2553.687 2762.5719 2643.858 2683.4074 2614.464 2548.686 2673.674 2711.875\n4 2307.775 1807.1985 1984.652 2056.5946 2199.979 1968.635 2085.315 2204.037\n5 2672.389 2895.4653 2774.489 2856.4430 2925.412 2709.362 2713.056 2797.438\n6 1217.476  988.5004 1277.886  958.9049 1233.710 1553.810 1217.393 1407.077\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3486.999 3241.396 3534.186 3276.522 3195.156 3194.460 3127.410 3527.293\n2 1976.136 1894.417 1917.752 1895.921 1881.436 1939.232 1915.321 1901.565\n3 2894.233 2617.379 2868.236 2654.691 2683.122 2733.537 2650.878 2881.359\n4 2256.069 1638.182 2137.911 1824.251 2476.903 2319.909 2231.990 2045.117\n5 2983.087 2823.992 3097.026 2936.095 2797.848 2605.175 2861.635 3007.561\n6 1111.391 1226.277 1335.425 1234.551 1483.838 1284.551 1613.268 1034.685\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3182.156 3630.883 3224.312 3633.954 3208.265 3408.814 3347.761 3458.273\n2 1851.440 1776.356 1957.122 1805.326 2064.580 1825.688 1962.320 1882.116\n3 2662.654 2812.733 2684.032 2977.378 2709.513 2726.413 2752.270 2807.932\n4 2031.840 1794.644 1827.740 2125.736 2318.395 1924.930 2269.979 1861.852\n5 2745.071 3305.833 2868.207 3160.599 2807.600 3019.519 2993.723 3039.997\n6 1294.547 1291.140 1324.942 1331.583 1066.104 1108.268 1367.073 1219.529\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3235.733 3284.522 3654.696 3483.355 3195.154 3457.828 3493.425 3480.368\n2 1960.222 1902.698 1590.263 2038.125 1965.654 1998.846 1692.942 2072.671\n3 2624.922 2698.122 2913.561 2855.812 2684.980 2893.230 2696.342 2872.711\n4 1872.353 2080.000 2291.969 1995.724 1985.413 2416.089 1933.295 1905.992\n5 2993.388 2858.659 3156.633 3050.696 2798.732 2894.788 3075.161 3107.567\n6 1217.256 1403.249 1187.675 1241.325 1424.571 1281.168 1100.044 1239.061\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3337.459 3360.710 3482.968 3633.109 3198.880 3230.181 3481.889 3372.424\n2 1942.189 1749.763 1658.388 1855.945 1960.935 1982.567 1966.556 2014.410\n3 2736.412 2755.621 2848.947 2997.762 2711.561 2677.360 2818.201 2714.747\n4 1718.290 2204.356 2128.121 2325.120 2058.480 2192.252 2087.134 1923.266\n5 2912.431 2946.012 3012.074 3147.367 2700.922 2829.598 3095.297 2960.076\n6 1400.575 1412.326 1363.499 1399.339 1189.094 1309.801 1152.901 1076.409\n     .pred    .pred    .pred     .pred    .pred    .pred    .pred    .pred\n1 3257.686 3575.140 3289.813 3205.3226 3230.207 3075.684 3430.493 3291.303\n2 1952.954 2011.978 1905.543 1906.3546 2252.210 1985.800 1879.943 2107.285\n3 2762.697 2862.976 2655.979 2695.7785 2719.757 2575.256 2746.411 2799.002\n4 2202.712 2231.443 2281.801 2162.9811 1755.030 2072.726 2125.133 2364.566\n5 2801.257 3191.437 2981.448 2637.4215 3007.755 2738.056 3022.706 2787.000\n6 1224.579 1096.995 1341.192  853.4363 1310.103 1162.044 1315.309 1080.877\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3578.973 3184.551 3324.401 3290.306 3553.568 3383.029 3135.907 3212.279\n2 1975.309 1742.012 2085.225 1967.269 1846.855 2044.602 2102.011 1886.037\n3 2986.759 2552.720 2825.206 2722.668 2822.936 2891.963 2625.031 2711.947\n4 2090.035 2009.350 2305.294 2173.998 2067.172 2114.098 2098.657 2158.145\n5 3078.006 2853.136 2829.025 2854.198 3237.258 2845.469 2771.104 2884.126\n6 1406.462 1503.145 1236.809 1085.258 1574.989 1157.541 1292.778 1600.564\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3214.328 3345.495 3632.000 3268.329 3433.312 3259.679 3131.723 3146.721\n2 2011.357 2240.710 1949.058 1849.585 1867.301 2094.887 1969.525 1696.808\n3 2685.781 2797.114 3048.161 2666.451 2737.715 2733.970 2699.534 2539.702\n4 2294.880 1972.831 2238.351 2003.569 1845.547 1913.302 2209.411 2041.911\n5 2765.767 3042.692 3074.365 2764.612 3142.581 3006.163 2696.805 2811.457\n6 1019.233 1178.432 1383.009 1157.446 1417.962 1419.614 1404.037 1516.060\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3368.736 3249.351 3294.376 3108.226 3533.739 3463.348 3032.727 3257.467\n2 2125.682 1926.165 2036.466 1803.810 1739.485 1960.936 1933.367 1883.896\n3 2775.409 2729.748 2768.272 2443.104 2925.860 2797.806 2542.883 2739.436\n4 2181.960 2068.042 2116.193 1941.784 2408.764 1952.354 2005.659 2256.976\n5 3079.050 2841.088 2871.340 2851.496 2857.059 3064.146 2723.182 2836.149\n6 1184.108 1496.382 1267.776 1196.385 1287.100 1158.517 1159.478 1410.499\n     .pred    .pred    .pred     .pred    .pred    .pred    .pred    .pred\n1 3158.248 3300.663 3404.125 3390.6052 3378.205 3367.183 3127.435 3300.077\n2 2127.788 1997.420 1743.207 1987.6110 1785.187 1549.035 1800.656 1859.152\n3 2670.143 2745.017 2784.706 2707.6850 2755.342 2776.849 2558.938 2697.840\n4 2147.938 1978.161 2215.388 2129.1066 2164.102 2668.513 1875.592 2000.025\n5 2798.145 2938.137 2928.312 3036.6966 2969.370 2863.398 2769.840 2868.880\n6 1172.123 1356.166 1340.776  967.1491 1267.382 1630.399 1104.735 1251.071\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred     .pred\n1 3337.256 3247.142 3358.264 3390.491 3298.383 3234.072 3169.213 3317.0923\n2 1988.849 1998.910 2224.924 2009.440 2029.944 2013.399 1877.283 1978.0506\n3 2713.448 2721.086 2919.492 2773.868 2726.146 2623.620 2665.005 2802.5207\n4 2230.051 1918.859 2155.988 1860.646 1765.048 1705.264 2147.014 2286.4656\n5 3010.392 2892.673 2852.690 3033.995 2917.371 2969.687 2690.761 2821.5010\n6 1289.054 1254.054 1297.103 1301.584 1032.925 1263.245 1182.952  939.2775\n     .pred    .pred     .pred    .pred    .pred    .pred    .pred    .pred\n1 3238.332 3273.311 3275.9247 3216.096 3175.977 3109.750 3319.812 3501.120\n2 1815.890 1940.073 2072.5367 1993.301 1848.007 1867.332 1942.289 2067.555\n3 2703.781 2754.718 2754.2528 2751.035 2628.739 2486.034 2732.572 2821.000\n4 2272.409 2232.420 1954.2038 2140.083 2004.868 1798.221 1911.984 1692.998\n5 2879.279 2811.986 2825.0808 2719.468 2757.071 2903.646 2904.424 3205.242\n6 1484.697 1277.997  968.4999 1259.054 1166.658 1272.207 1305.486 1223.657\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3043.977 3212.370 3244.176 3174.165 3278.794 3314.914 3208.188 3456.113\n2 2080.407 1912.571 1975.203 1892.939 1814.087 1869.200 1900.245 1832.479\n3 2608.879 2673.672 2686.283 2595.757 2665.308 2755.633 2685.956 2845.969\n4 1875.395 2078.314 1997.541 1954.454 1855.280 2055.253 2039.079 2088.654\n5 2759.737 2806.565 2813.881 2834.740 2865.966 2912.893 2696.969 2928.247\n6 1464.585 1261.067 1247.181 1126.485 1251.647 1324.567 1038.632 1225.500\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3095.871 3310.067 3255.794 3229.663 3217.471 3119.952 3340.898 3195.920\n2 1918.537 2002.579 2050.772 1976.957 1986.808 2094.726 1813.163 1961.078\n3 2554.776 2736.723 2839.572 2804.218 2689.223 2678.865 2765.383 2583.224\n4 1716.858 2195.991 2328.231 2589.620 2036.987 1951.794 2499.849 1913.338\n5 2827.594 2973.641 2770.847 2767.182 2874.889 2769.102 2757.772 2936.143\n6 1414.117 1279.994 1306.833 1358.043 1522.703 1583.621 1237.251 1304.434\n     .pred    .pred     .pred    .pred    .pred    .pred    .pred    .pred\n1 3367.058 3208.561 3376.2145 3519.190 3292.893 3343.602 3242.316 3252.617\n2 2227.569 2077.440 2024.8161 2033.358 2157.151 1908.626 1931.240 1978.652\n3 2884.677 2636.351 2832.0753 2972.003 2750.049 2749.219 2668.853 2855.421\n4 2220.186 2136.016 2116.2641 2251.489 2070.922 1902.764 1883.236 2449.340\n5 2957.226 2868.201 2824.6285 3054.848 2925.850 2957.300 2912.032 2662.316\n6 1204.925  960.619  835.4799 1559.313 1246.249 1432.644 1341.632 1235.854\n     .pred    .pred    .pred    .pred    .pred    .pred    .pred    .pred\n1 3439.233 3380.633 3535.200 3052.340 3283.546 3527.165 3057.187 3302.797\n2 2162.569 2074.447 1917.146 1892.227 1942.372 1993.357 2012.619 1968.965\n3 2805.088 2756.247 2885.753 2598.147 2745.762 2821.943 2618.487 2614.064\n4 1893.177 1848.939 1990.605 2303.222 2158.080 1807.764 2200.240 2020.771\n5 3154.140 3043.346 3074.643 2680.017 2841.991 3186.727 2689.323 3022.012\n6 1025.950 1379.659 1175.683 1363.338 1027.321 1180.127 1194.353 1084.918\n\n#Transpose to have samples as rows and data points as columns\npredictions_df &lt;- t(predictions_df)\n\n#Calculate median and 95% confidence intervals\npreds &lt;- predictions_df |&gt; apply(2, quantile,  c(0.025, 0.5, 0.975)) |&gt; t()\n\n\n#Make a data frame for plotting\nplot_data &lt;- data.frame(\n  truth = train_data$Y,\n  point_estimate = model2_res$pred,\n  median = preds[,2],\n  lower_ci = preds[,1],\n  upper_ci = preds[,3]\n)\n\n#Plot observed values vs. estimates\nggplot(data = plot_data, aes(x = truth)) +\n  geom_point(aes(y = point_estimate, color = \"Point Estimate\"), size = 2) + #Original predicted value\n  geom_point(aes(y = median, color = \"Median Prediction\"), size = 2) + #Median predicted value from bootstrapping\n  geom_point(aes(y = lower_ci, color = \"Lower 95% CI\"), size = 1, alpha = 0.7) + #Lower bound of 95% CI\n  geom_point(aes(y = upper_ci, color = \"Upper 95% CI\"), size = 1, alpha = 0.7) + #Upper bound of 95% CI +\n  geom_abline(intercept = 0, slope = 1) +\n  scale_x_continuous(limits = c(0, 5000)) +\n  scale_y_continuous(limits = c(0, 5000)) +\n  labs(\n    x = \"Observed Values\",\n    y = \"Predictions\",\n    title = \"Observed Values vs. Predictions\"\n  ) +\n  scale_color_manual(\n    name = \"Legend\", \n    values = c(\n      \"Point Estimate\" = \"black\",\n      \"Median Prediction\" = \"blue\",\n      \"Lower 95% CI\" = \"red\",\n      \"Upper 95% CI\" = \"purple\"\n    )\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nThe bootstrapping predictions perform about the same as the original model with all predictors, as the median values largely overlap with the point estimates, and their distributions about the 45 degree line are similar.\nPart 3\n\n# Generating Predictions from Test data\ntest_lm_two &lt;- predict(lm_y_all, new_data = test_data)\n\n# calculate metrics from test data\nrmse_test_lm_two &lt;- tibble(truth = test_data$Y, predicted = test_lm_two$.pred)%&gt;%\n  metrics(truth = truth, estimate = predicted)\n\n# output\nrmse_test_lm_two\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     627.   \n2 rsq     standard       0.562\n3 mae     standard     486.   \n\n\n\n# Plot\n# create df for plotting\ntrain_plot_data &lt;- tibble(Observed = train_data$Y, Predicted = all_predictions_lm$.pred, Dataset = \"Training\")\ntest_plot_data &lt;- tibble(Observed = test_data$Y, Predicted = test_lm_two$.pred, Dataset = \"Test\")\n\n# combine dfs\nplot_data &lt;- bind_rows(train_plot_data, test_plot_data)\n\n# plot predicted vs observed with different colors for training and test\nggplot(plot_data, aes(x = Observed, y = Predicted, color = Dataset)) +\n  geom_point(alpha = 0.5, size = 2) +  # Reduce opacity and increase point size for overlapping points\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"black\") +\n  scale_color_manual(values = c(\"Training\" = \"red\", \"Test\" = \"blue\")) +\n  labs(title = \"Predicted vs Observed Values\",\n       x = \"Observed Y\",\n       y = \"Predicted Y\",\n       color = \"Dataset\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis week’s exercise started with seed setting to ensure reproducibillity and creating a new data frame with variables of interest using week eight’s data. After this, the data was split into a 75% training and 25% testing set. The models from week eight (Model 1 = just dose as predictor. Model 2 = dose, age, sex, weight, and height as predictors) were fitted using the training data. These models were the nassessed using RMSE. Additionally, a null model was created. Model 2 performed the best, having the lowest RMSE.\nAfter the intial fitting, a 10-fold cross-validation was done. This process fitted the two models ten times each, constituing about 90% of the data. The other 10% was used to evaluate the fit by computing the RMSE of the model.\nRegarding overall model assessment, both models performed better (in terms of RMSE) than the null model. Model 1 having better results than the null makes sense. Presumably, knowing the dose helps towards predicting Y rather than no predictors at all. This could be difficult to use for real applications as the model is very simple. Model 2 also improves upon model 1. Logically, this makes sense considering the factors, like height and weight, that go into drug concentration. I would consider the model usable as the predictors are generally easy to measure and have logical sense in predicting drug concentration.The model is also interpretable as there is not too many predictors involved."
  }
]